% test citing
%\cite{CFried:Privacy}
%\cite{WarrenBrandeis:RightToPrivacy}
%\cite{sep-privacy}
%\cite{7ToP}
%\cite{Grimm:ItSecRefModel}
%\cite{ItSecGlossary}
%\cite{SociotechnicalArchitectureForOnlinePrivacy}
%\cite{EUDataProtectionDirective}
%\cite{EUConventionOnHumanRights}
%\cite{Bundesdatenschutzgesetz}
%\cite{Gutwirth:DefiningPrivacy}
%\cite{UKDataProtectionAct}

\chapter{Legal and Ethical aspects of Privacy}
\label{chap:privacy}

\newcommand{\om}{[...]\xspace} % omission
%\newcommand{\om}{\ldots} % omission

As privacy is a very general and hard to grasp term, we need to fix a definition of privacy that is suitable for our needs.
As background information we include an overview about historical treatments of privacy as well as legal regulation of privacy in the European Union.
Based on this we propose a definition of privacy as {\em control over personal data}, and introduce seven privacy types that give specify the term {\em personal data} in the context of mobile sensor data collection.

% \section{Histrocial Approaches to Privacy}

\section{Legal Aspects of Privacy}

In the following sections we outline the most relevant legislature regarding privacy protection,
from on European angle.
Of particular importance is the EU Directive 95/46/EC that is discussed in section \ref{EUDIR}.

Based on the legal background presented here, we will derive the legal privacy requirements for our systems in \ref{sec:LEGAL_REQ}.

\subsection{European Convention on Human Rights}

The \emph{Europen Convetion on Human Rights} \cite{ECHR} was created by the members of the \emph{Council of Europe} (CoE) in 1953 as part of the aftermath of the second world war.
It formulates universal rights of citizens against the state authority.
All member states of the Council of Europe, which includes all EU members, have incorporated this convention into their national law.

Article 8 of the ECHR contains a protection of personal data.

\begin{quote}
(1) Everyone has the right to respect for his private and family life, his home and his correspondence.

(2) There shall be no interference by a public authority with the exercise of this right except such as is in accordance with the law and is necessary in a democratic society in the interests of national security, public safety or the economic well-being of the country, for the prevention of disorder or crime, for the protection of health or morals, or for the protection of the rights and freedoms of others.
\end{quote}

The protection of personal data under Article 8 is not an absolute law but must be considered in relation to other laws such as the freedom of expression (ECHR, Art. 10).
The \emph{European Court of Human Rights} (ECtHR) overseas the implementation of this directive and has adopted a rather broad interpretation of the article.\footnote{\url{http://en.wikipedia.org/wiki/Article_8_of_the_European_Convention_on_Human_Rights}}

In particular State actions of searching a persons home, gathering and storing information in a secret police file, and stopping a prisoner's communication have been ruled to interfere with Article 8.

In the context of the Live+Gov project the ECHR is of limited relevance, since the Live+Gov System is offered by private companies and not directly by the State authority.

\subsection{OECD Guidelines and CoE Convention 108}

The emergence of information technologies that allow automated processing of personal data made more detailed rules for safeguarding the privacy of citizens necessary.
In the light of this developments the OECD  \cite{OECD80} issued Guidelines on Protection of Privacy in 1980 which establish the following basic principles of data protection:
\begin{enumerate}
\item Collection Limitation Principle.
  There should be limits to the collection of personal data and any such data should be obtained \om with the knowledge or consent of the data subject.
\item Data Quality Principle.
  Personal data should be relevant to the purposes for which they are to be used, and,  \om accurate, complete and kept up-to-date.
\item Purpose Specification Principle.
  The purposes for which personal data are collected should be specified \om and the subsequent use limited to the fulfillment of those purposes \om.
\item Use Limitation Principle.
  Personal data should not be disclosed \om except: a) with the consent of the data subject; or b) by the authority of law.
\item Security Safeguards Principle.
  Personal data should be protected by reasonable security safeguards \om.
\item Openness Principle.
  {\om} Means should be readily available of establishing the existence and nature of personal data, and the main purposes of their use, as well as the identity and usual residence of the data controller.
\item Individual Participation Principle.
  An individual should have the right
  \begin{itemize}
  \item to obtain from a data controller, or otherwise, confirmation of whether or not the data controller has data relating to him;
  \item to have communicated to him, data relating to him \om
  \item \om to have the data erased, rectified, completed or amended.
  \end{itemize}
\item Accountability Principle.
  A data controller should be accountable for complying with measures which give effect to the principles stated above.
\end{enumerate}

Where the following definitions are understood.
\begin{itemize}
\item \emph{personal data} means any information relating to an identified or identifiable person (\emph{data subject}).
  An identifiable person is one who can be identified either directly, by reference to a name or identification number or indirectly, by one or more factors which make it possible to find out who the data subject is by conducting further research.
\item a \emph{data controller} means any party who is competent to decide about the contents and use of personal data.
\end{itemize}

The OECD guidelines were adopted by EU law in the Strassbourg Convention 108 of the Council of Europe \cite{CONV108} in 1981.

Relevant for our investigations is in particular, that sensor data collected from mobile devices is considered personal data if the individual can be identified based on the data by any direct or indirect means.
Therefore the above principles apply.

% UPDATE 2013: http://www.oecd.org/sti/ieconomy/privacy.htm

\subsection{EU Data Protection Directive}\label{EUDIR}

The \emph{Directive 95/46/EC} of 1995 \cite{DIR95} is the fundamental regulation of data protection in the European Union.
It was designed to give further substance to the Convention 108.
In particular it makes the creation of an independent supervisory authority necessary (Art. 28).
As this text is the main legal basis for our investigation we review it in detail.
In Section \ref{sec:ECIMPL} the status of the implementation is discussed in some example cases.

The interpretation and oversight of the Directive lies at the Court of Justice of the European Union (CJEU).
A summary of the most important rulings can be found in Handbook on European data protection law \cite{EU_HANDBOOK_2014}.

The ambition of the Directive is stated at the very beginning.
\begin{quote}
  (Art. 1.1) In Accordance with this Directive the Member States shall protect the fundamental rights and freedoms of natural persons, and in particular their right to privacy with respect to the processing of personal data.
\end{quote}

The Directive follows the definition of personal data, data subject, and data controller of the OECD Guidelines (cf. Art. 2).
Furthermore it introduces the role of a \emph{processor} as a person which processes, by wholly or partly automatic means (Art 3.), personal data on behalf of the controller.

Data collection of intelligence agencies and the police is not restricted by the Directive (Art. 3).

The most important articles are summarized in the following paragraphs.
In order to keep the text more readable we have simplified the formulation by removing the formulation ``Member States shall provide that ...'' from each paragraph.
\begin{itemize}
\item (Art. 6.1.a) Personal data must be processed fairly and lawfully.

[The meaning of the term 'fair processing' is entailed in the following articles.
In particular transparency of processing, information of the data subject, and right to access the data are implied (cf. \cite{EU_HANDBOOK_2014})]

\item (Art. 6.1.b) \emph{Specification of Purpose.} Personal data must be collected for specified, explicit and legitimate purposes and not be processed in a way incompatible with this purposes.

Further processing of data for historical, statistical or scientific purposes shall not be considered incompatible \om.

\item (Art. 6.1.c) Personal data must be adequate, relevant and non-excessive in relation to the purposes \om.

\item (Art. 6.1.d) \emph{Accuracy.} Personal data must be accurate and \om every reasonable step must be taken to ensure that data which is inaccurate or incomplete \om are erased or rectified.

\item (Art. 6.1e) Personal data must be kept in a form which permits identification for no longer than is necessary \om.
% \item (Art. 6.2) It shall be for the controller to ensure that (Art. 6.1) is complied with.
\end{itemize}

In addition to strengthening the OECD Data Quality Principle in Article 6, the Directive requires a strong form of consent of the data subject, before any collection or processing of data can take place.

\begin{itemize}
\item (Art. 7). Personal data may be processed only if:
  \begin{itemize}
    \item [(a)] the data subject has unambiguously given his consent; or
    \item [(..)] [exceptions are made for performance of a contracts with the data subject,  legal obligations of the controller, to protect vital interests of the data subject, the public interest and]
     \item [(f)] the processing is necessary for purposes of legitimate interests pursued by the controller or by a third party to whom the data are disclosed, except where such interests are overridden by the interests \om of the data subject which require protection under Art. 1(1).
  \end{itemize}

\item (Art. 8.1) \emph{Special Categories.} Member Stats shall prohibit the processing of personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, trade-union membership, and the processing of data concerning health or sex life. [Art. 8.2 lists several exceptions, including explicitly explicit consent of the data subject.]
\end{itemize}

The OECD Participation Principle is addressed and extended in the following articles.

\begin{itemize}
\item (Art. 10, 11) The controller \om must provide a data subject \om with the following information:
  \begin{itemize}
    \item [(a)] the identity of the controller \om
    \item [(b)] the purpose of processing for which the data are intended;
    \item [(c)] any further information \om that is necessary to guarantee fair processing in respect of the data subject. [This includes in particular the recipients of the data, the existence of the right to of access and the right to rectify the data.]
  \end{itemize}

\item (Art. 12) \emph{Right to Access.} Every data subject has the right to obtain from the controller
\begin{itemize}
  \item (a) \om confirmation as to whether or not data relating to him are being processed \om, communication to him \om the data undergoing processing and any available information as to their source, knowledge of the logic involved in any automatic processing \om;
  \item (b) the rectification, erasure or blocking of data the procession of which does not comply with the provisions of this Directive \om;
  \item (c) notification to third parties to whom the data have been disclosed \om.
\end{itemize}

%\item Confidentiality of Processing (Art. 16).
%Any person under the authority of the controller or of the processor \om who has access to personal data must not process them except on instructions from the controller, unless he is required to do so by law.
\end{itemize}

A similar form of the Security Safeguard Principle is contained in Article 17.

\begin{itemize}
\item (Art. 17) \emph{Security of processing.}
The controller must implement appropriate technical and organizational measures to protect personal data against accidental loss, alteration, unauthorized disclosure or access \om and against all other forms of unlawful processing.

[The level of security has to be balanced against the risk of processing.]

% Having regard to the state of the art and the cost of their implementation, such measures shall ensure a level of security appropriate to the risk represented by the processing and the nature of the data to be processed.
\end{itemize}

Furthermore the Directive demands all data processing to be reported to a supervisory authority.
This obligation can be lifted if an internal data protection official is appointed, who is responsible in particular for keeping a processing register, that has to be made available on request.

\begin{itemize}
\item Notification (Art. 18. 1).
The controller \om must notify the supervisory authority referred to in Article 28 before carrying out any wholly or partly automatic processing operation \om.

\item (Art. 18.2).
Simplification or exemption from notification may be provided only under the following conditions: \om where the controller \om appoints a personal data protection official, responsible in particular:
\begin{itemize}
\item for ensuring in an independent manner the internal application of the national provisions taken pursuant to this directive.
\item for keeping the register of processing operations carried out by the controller, containing the items of information referred to in Article 21 (2)
\end{itemize}
thereby ensuring that the rights and freedoms of the data subjects are unlikely to be adversely affected by the processing operations.

\item (Art. 19.1)
The information to be given in the notification shall include at least:
\begin{itemize}
  \item [(a)] the name and address of the controller \om;
  \item [(b)] the purpose \om of processing;
  \item [(c)] a description of the category \om of the data \om;
  \item [(d)] the recipients \om to whom the data might be disclosed;
  \item [(e)] proposed transfer of data to third countries;
  \item [(f)] a general description allowing a preliminary assessment to be made of the appropriateness of the measures taken pursuant of Article 17 to ensure the security of processing;
\end{itemize}

\item (Art. 21.2) \emph{Publication}.
A register of processing information \om shall be kept at the supervisory authority.
The register shall contain at least the information listed in Article 19.1 (a) to (e).

The register may be inspected by any person.

\item (Art. 21.3). In relation to processing operations not subject to notification, that controllers \om make available at least the information referred to in Article 19.1 (a) to (e) in an appropriate form to any person on request.

\item (Art. 28) \emph{Supervisory Authority.}
Each Member State shall provide that one or more public authorities are responsible for monitoring the application \om of this Directive.

These authorities shall act in complete independence in exercising this functions entrusted to them.
\end{itemize}

Data transfer to third countries outside of the EU requires those countries to have an adequate level of data protection.
\begin{itemize}
\item (Art. 25.1) \emph{Transfer to third countries.}
The transfer to a third country of personal data \om may take place only if \om the third country in question ensures an adequate level of protection.
\end{itemize}
The European Commission can decide whether a third country ensures an adequate level of protection (Art 25.6).
The USA, is not considered to do so.
Data exchange between the US and EU is possible under the Safe Harbor regulation \cite{SAFE_HABOR}.
Further Exceptions are provided by the Passenger Name Record Agreement \cite{PNR}.

\subsection{Implementation of the Data Protection Directive}\label{sec:ECIMPL}

\textbf{Germany}.
Germany implements Directive 95/46 with the \emph{Bundesdatenschutzgesetz (BDSG)}
of 2001. However, Germany has violated the directive in two points:
\begin{enumerate}
\item The BDSG has become effective three years too late, thus the EC filed a treaty violation proceeding against Germany.
\item The BDSG does not implement independent supervisory authorities.
The Bundesdatenschutzbeauftragter is subordinate to the Ministry of Interior.
Although he is not subject to technical oversight (\emph{Fachaufsicht}), he is subject to staff supervision by the government (Rechtsaufsicht, Dienstaufsicht) and budget oversight by the ministry.
In March 2010 Germany was found guilty of violation of Directive 95/46 by the ECJ.
\end{enumerate}

The states of Germany have their own implementation of Directive 95/46 (\emph{Landesdatenschutzgesetze}).
Federal public authorities are only bound to their federal law.
Churches are not subject the BDSG.

\textbf{United Kingdom.} %TODO: HOW MUCH IS COPY PASTE FROM WIKIPEDIA?
The UK implements Directive 95/46 with the \emph{Data Protection Act 1998} (DPA).

The act is known for its high complexity: a manual record of phone numbers for business purposes could be hold subject to the DPA.
Although the act seems to fully cover the directive.
Even higher restriction apply for \emph{``sensitive personal data''} (race, ethnicity, politics, religion, trade union status, health, sex life or criminal record), i.e. consent must be given freely and has to be explicit.

The Act's definition of personal data covers any data that can be used to identify a living individual.
Anonymised or aggregated data is not regulated by the Act, providing the anonymisation or aggregation has not been done in a reversible way.

The Freedom of Information Act 2000 modified the act for public bodies and authorities, and the Durant case modified the interpretation of the act by providing case law and precedent.

The Data Protection Act creates rights for those who have their data stored, and responsibilities for those who store, process or transmit such data.
The person who has their data processed has the right to:
\begin{itemize}
\item View the data an organization holds on them.
A `subject access request' can be obtained for a nominal fee.
As of January 2014, the maximum fee is \pounds2 for requests to credit reference agencies, \pounds50 for health and educational request, and \pounds10 per individual otherwise.
\item Request that incorrect information be corrected.
If the company ignores the request, a court can order the data to be corrected or destroyed, and in some cases compensation can be awarded.
\item Require that data is not used in any way that may potentially cause damage or distress.
\item Require that their data is not used for direct marketing. \cite{3}
\end{itemize}


\textbf{United States of America}
The USA do not implement the directive, nor is there any obligation for them to do so.
However, companies subject to US jurisdiction can be certified to comply with the seven principles enforced by Directive 95/46.
Thus, those companies will act as \emph{safe harbors}.
Without certification foreign companies are not allowed to store and process customer data in their country.


\subsection{EU Charter of Fundamental Rights}
The Treaty of Lisbon of 2007, which introduced the fundamental functioning of the European Union
includes the \emph{Charter of Fundamental Rights of the Europen Union} \cite{EUFR2010}.
This Charter summarizes the full range of civil, political and economic rights of EU citizens and contains the following two articles that safeguard the privacy of the citizen.

\begin{quote}
  Article 7. Respect for private and family life.\\
  Everyone has the right to respect for his or her private and family life, home and communications.

  Article 8. Protection of personal data.
  \begin{enumerate}
    \item [(1)] Everyone has the right to the protection of personal data concerning him or her.
    \item [(2)] Such data must be processed fairly for specified purposes and on the basis of the consent of the person concerned or some other legitimate basis laid down by law.
      Everyone has the right of access to data which has been collected concerning him or her, and the right to have it rectified.
    \item [(3)] Compliance with these rules shall be subject to control by an independent authority.
  \end{enumerate}
\end{quote}

Although the Charter does not extend the pre-exiting Directive 95/46/EC, it amplifies the importance of this privacy protection as a fundamental right.

\section{Privacy Definition and Taxonomy}
\label{sec:taxonomy}

\subsection{Defining Privacy}

% TODO: Expand this section!!

Defining privacy is a challenge which seems impossible. This is well put to words by Serge Gutwirth, who notes in \cite{Gutwirth}:

\begin{quote}
The notion of privacy remains out of the grasp of every academic chasing it. Even when it is cornered by such additional modifiers as `our' privacy, it still finds a way to remain elusive.
\end{quote}

Many privacy researchers seem to ``focus on the ways in which privacy can be infringed'' \cite{1}.
Thus they try to create taxonomies of \emph{privacy harms} instead of taxonomies of \emph{privacy types}.
Those two differ in the respect that the former focuses on threats to prohibit whereas the latter focuses on values to protect.
So one should rather evaluate what aspects are precious about privacy and develop measures to ensure their security than only forbid single actions against privacy \cite{1}.

%% TODO %%

* We follow Fried in defining privacy as the ability to control data about personal information.

* What is the relation to legal aspects?

* What should be personal information?

* Use Seven Privacy Types be Friedewald, Finn and Wrigtht.

\subsection{The Seven Types of Privacy}

Seven Types of Privacy based on four types of privacy by Clarke.
Clarke's four types are outdated by contemporary technologies and no longer adequate.
In order to fix this Friedewald, Finn and Wright extend the former four to the now introduced seven types privacy as follows:

\begin{enumerate}

\item \textbf{Privacy of the Person.}

This type is the right keep body functions and body characteristics private.

Examples include:
\begin{itemize}
\item Body Characteristics: weight, height, shoulder width, \ldots
\item Biometric Properties: Fingerprints, DNA Sequence, \ldots
\item Medical Conditions: Orthopedic conditions (e.g.~limping), Having a cold, \ldots
\end{itemize}

\item \textbf{Privacy of Behaviour and Action}

This type is also concerned with the ``protection against disclosure of personal matters'' through behaviour, however Clarke's distinction between ``casual observation \om systematic recording and storage of information about those activities'' is lifted.

Examples include:
\begin{itemize}
\item regular visit at church, bakery, doctors
\item sexual habits
\item political activities
\end{itemize}

\item \textbf{Privacy of Communication}

It ``aims to avoid the interception of communications'' either electronic or face-to-face.

Examples include:
\begin{itemize}
\item Contents of letters and emails
\item Personal direct communication
\item Right to free discussion, i.e.~without third parties listening
\end{itemize}

\item \textbf{Privacy of Data and Image}

This type is concerned with ``making sure that individual's data is not automatically available to other individuals and organizations''.
This is Informational Privacy in an intuitive sense.

Examples include:
\begin{itemize}
\item Phone number
\item IP address
\item Public-administrative Data (Date of Birth, Melderegister)
\item Data held by organizations, like Banks or Insurance Companies
\item All data that is stored in online services (facebook)
\end{itemize}

\item \textbf{Privacy of Thoughts and Feelings}

This type is the right ``not to share their thoughts or feelings or to have those thoughts or feeling (sic!) revealed''.
It is concerned with (automatic) emotion detection.
This type is the counterpart the Privacy of the Person like body and mind are counterparts of one another (dualism).

Examples include:
\begin{itemize}
\item Current feeling: Depression, tiredness, stressed, awake
\item Thoughts in general.
\end{itemize}

\item \textbf{Privacy of Location and Space}

This type is the right ``to move about in public or semi-public space without being identified, tracked or monitored''.
Additionally this type is concerned with the protection of one's home and private places (``right to solitude''.

Examples include:
\begin{itemize}
\item GPS position tracking
\item Location of home address
\end{itemize}

\item \textbf{Privacy of Association}

This type is the right ``to associate with whomever [one] wishes, without being monitored''.
It is concerned with the protection against the automatic record of one's contacts.
It does not imply that one is monitored because of the associations.

Examples include:
\begin{itemize}
\item Friends
\item Joining of organizations (e.g.~political parties)
\end{itemize}
\end{enumerate}

\subsection{Privacy Type Inferences}

The above types of privacy types are not disjoint to each other.
For example if the location of a citizen is known it is possible to infer information about political associations (e.g. his visits to a party meeting).
In this section we explore possibilities how personal data can be inferred from each other.
Our findings are summarized in Figure \ref{figure:Implicit Privacy Violation Matrix}.

\paragraph*{1. Privacy of The Person}

The Privacy of The Person is concerned with one's biometric privacy.
If this type is violated, following implicit violations are possible:

\begin{itemize}
\item [(1-5)]
  Privacy of Thoughts and Feelings. Some psychological diseases
  (e.g.~depression) have physiological impact. Such physiological
  patterns could be detected.
\end{itemize}

\paragraph*{2. Privacy of Behaviour and Action}

The Privacy of Behaviour and Action is concerned with one's social, political, religious, sexual, etc. activities.
If his type is violated, following implicit violations are possible:

\begin{itemize}
\item [(2-1)] Privacy of The Person.
  Religious practices which include body modifications (e.g.~circumcision).
\item [(2-5)] Privacy of Thoughts and Feelings.
  Social activities in general depend on a certain intellectual attitude.
  Such an activity is the expressions of such an attitude.
\item [(2-7)] Privacy of Association.
  Recording religious, political or sexual activities can reveal association with churches, political parties or sexual partners.
\end{itemize}

\paragraph*{3. Privacy of Communication}

The Privacy of Communication is concerned with not having such communication (correspondence or vis-a-vis) intercepted.
This is very broad type of privacy.
Depending on the contents of the intercepted communication every other type can be violated:

\begin{itemize}
\item [(3-1)] Privacy of The Person. Communication about body characteristics.
\item [(3-2)] Privacy of Behaviour and Action. Communication about social activities.
\item [(3-4)] Privacy of Data and Image.
  Communication containing one's passwords or other sensitive data.
\item [(3-5)] Privacy of Thoughts and Feelings.
  Communication of thoughts and feelings, e.g.~wiretapping a flirt or a catholic confession
  ritual.
\item [(3-6)] Privacy of Location and Space.
  Interception of face-to-face communication is only possible if one's location and space is violated (wiretapping).
\item [(3-7)] Privacy of Association.
  Communication about one's associations (family members, churches, etc.).
\end{itemize}

\paragraph*{4. Privacy of Data and Image}

The Privacy of Data and Image is concerned with one's data not being automatically available to others.
This also is a very broad type of privacy.
Depending of the data or image contents every other type can be violated:

\begin{itemize}

\item [(4-1)] Privacy of The Person.
  Images or stored biometric information reveal one's physical characteristics.
\item [(4-2)]Privacy of Behaviour and Action.
  Images or diaries can reveal one's social activities.
\item [(4-3)]Privacy of Communication.
  Modern communication systems usually contain some sort of archive function, e.g.~E-mail clients do not automatically delete messages.
  Such messages are data and reveal one's communication.
\item [(4-4)]Privacy of Thoughts and Feelings.
  Images can show one's emotional state.
\item [(4-5)]Privacy of Location and Space.
  Images can reveal one's location, e.g.~making a picture in front of the Eifel Tower.
\item [(4-6)]Privacy of Association. E-mail data can also reveal
  association.
\end{itemize}

\paragraph*{5. Privacy of Thoughts and Feelings}

The Privacy of Thoughts and Feelings is concerned with keeping such
thoughts and feelings secret. If this type is violated, following
implicit violations are possible:

\begin{itemize}
\item [(5-1)] Privacy of The Person.
  Thoughts and feelings can reveal medical conditions.
\item [(5-2)] Privacy of Behaviour and Action.
  Thoughts and feelings can reveal a certain attitudes which create a foundation for certain   social activities.
\item [(5-7)] Privacy of Association.
  Thoughts and feelings can reveal individual association, e.g amorous feelings for a certain person.
\end{itemize}

\paragraph*{6. Privacy of Location and Space}

The Privacy of Location and Space is concerned with one's right to move freely without being tracked and one's right to private places.
If this type is violated, following implicit violations are possible:

\begin{itemize}
\item [(6-1)] Privacy of The Person.
  Frequently visited doctors can reveal certain medical conditions, if such doctors are known specialsts.
  In general it could imply illness.
\item [(6-2)] Privacy of Behaviour and Action.
  Frequently visited places in general can reveal association and hence implies social activities.
\item [(6-3)] Privacy of Communication.
  If one's location is knwon, it is possible to intercept (wiretap) one's communication.
  This also may violate the right to private spaces.
\item [(6-4)] Privacy of Data and Image.
  If one's location is known, it is possible shoot pictures.
\item [(6-5)] Privacy of Thoughts and Feelings.
  Frequently visited persons may imply certain thoughts and feelings, e.g.~having a mistress.
\item [(6-6)] Privacy of Association.
  Frequently visited places can reveal associations simply by searching in maps or yellow-pages.
\end{itemize}

\paragraph*{7. Privacy of Association}

The Privacy of Association is concerned with one's right to associate with whomever one wants, without that association having recorded.
If this type is violated, following implicit violations are possible:

\begin{itemize}

\item [(7-1)] Privacy of The Person.
  Association with tattoo artists could imply having tattoos or other body modifications.
\item [(7-2)] Privacy of Behaviour and Action.
  Association with churches or political organizations could imply certain activities.
\item [(7-5)] Privacy of Thoughts and Feelings.
  Association with churches of political organizations could imply a certain intellectual attitude.
\end{itemize}

%\includegraphics{../diagrams/png/implicit-privacy-violation-matrix.png}
\input{./figures/Implicit-Privacy-Violation-Matrix}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak

\chapter{Privacy Analysis of Live+Gov Systems}

The goal of this chapter to analyze and identify the threads to personal privacy that are posed by collecting, storing and processing sensor data from mobile phones.
We derive concrete privacy protection measures that address the main risks involved with handling such data.

The complexity of our systems and the variety of threads make a great number of counter measures plausible.
We approach this complexity with the aid of a general security analysis model developed in \cite{Grimm}.
We give a brief introduction to this model and perform a IT Security Analysis with respect to the privacy asset for our system.

\section{IT Security Analysis according to Grimm et. al}

We follow the Reference Model for IT Security Analyis as described in \cite{Grimm}.
It supersedes earlier efforts by \cite{Avizienis}.

The reference model consists of a \emph{model} and a \emph{procedure}.
The model aims to organize common security terminology in a reasonable and practical way.
The procedure describes a method to analysis the IT system based on that model.
In this section we give a brief overview over the reference model.

\subsection{Model}

%\includegraphics{../diagrams/png/itsec-ref-model-grimm.png}
\input{./figures/The-IT-Security-Reference-Model-Grimm}

The model is depictured in Figure \ref{fig:refmodel}.
It is organized in four views (round boxes) that contain a number of components (rectangular boxes).




The \emph{world view} contains all components describing the current state.
It consists of the following components:
\begin{itemize}
\item \textbf{Actors.}
All identifiable stakeholders of the system under study.
Typical actors include, users, developers, clients and criminals.

\item
\textbf{Assets.} Things of value to one or more stakeholders.
The value can be hard (money, data, etc.) or soft (trust, privacy,etc.).
In our case the only asset we are concerned with is the privacy of the citizen.

\item \textbf{IT-Systems.}
The relevant IT-Systems under study. This encompasses hardware (e.g. servers, network infrastructure), as well as software and third party services.
The level of granularity has to be detailed enough to express all possible threats to the assets at stake.

\item \textbf{Conflicts of Interests.}
Different actors have different interests which can be in conflict which each other.
These conflicts of interest are the origin of all attacks to the system.

A typical conflict is the \emph{Criminal-User-Conflict}:
A user wants to keep control over their private data.
A criminal wants to gain money.
The possibility of selling private data (user profiles) to advertisers, renders both interests conflicting.

\item \textbf{Vulnerabilities.}
All identifiable weaknesses in the IT-System.

In the example of the criminal-user-conflict, the criminal has to exploit a vulnerability, e.g. a weak password, to gain access to the private data abou the user.

\item \textbf{Interactions.}
This point captures all possible interactions between assets, IT-Systems, humans and vulnerabilites.
It is described in more detail in the next view.
\end{itemize}




The \emph{potential view} displays the intended and unintended interactions of the components in the world view.
The intended interactions support the underlying business objectives.
Unintended interactions lead to threats.
The potential view consists of the following components.
\begin{itemize}
\item \textbf{Business Objectives.}
Interaction of IT-system and actors that realize a business goals of the system owner.

\item \textbf{Threats.}
A threat is a potential interaction that destroys or harms assets of the system.
Concrete realizations of threats can be \emph{attacks} or \emph{accidents}.
Attacks are executed by an actor in response to a conflict of interest.
Accidents are harmful interactions that are not willfully caused by an actor.

\item \textbf{Chances/Risk.}
Evaluation of chances and risks associated to the business objectives and threats.
The risk associated to a threat is its expected loss.
A chance associated to a intended interaction is its expected gain.

In the case that, the loss can be quantified monetary, and the likelihood of occurrence of a threat can
be modeled probabilistically, the risk is given by the product
\[ \text{risk} = \text{loss} \cdot P[\text{threat}]. \]
In practice such a quantitative risk evaluation is often not possible, and a qualitative, heuristic, analysis is performed instead.

\item \textbf{Security Requirements.}
A set of interactions (e.g. threats) that shall not occur within the system in order to achieve its business objectives.
Security requirements are targeted to protect one or more assets.

An example of a security requirement is that a given communication channel shall not be infringed by criminals.
\end{itemize}




The \emph{concept view} is a realization of the the potential view of the system.
It specifies important interactions that require further planning.
It contains the following components:
\begin{itemize}
\item \textbf{Business Model.}
The plan to achieve business objectives.

\item \textbf{Accident Scenario.}
A concrete outline of an interaction that leads to an accident.
In particular the asset under threatened and exploited vulnerability need to be described.

\item \textbf{Attack Technique.}
A specific technique or technology to attack IT-Systems (Man in the Middle, Phishing, etc.).
In particular the attacking actor, the conflict of interest and the exploited vulnerability need to be described.

\item \textbf{Security Measures.}
It describes a plan of sufficient measures to secure the intended interactions and to aviod the unintended interactions.
Each security measure targets a vulnerability of the system in order to reduce a risk for a certain thread.
\end{itemize}




The \emph{event view} contains all actual events through out the lifetime of the system.
The event view instantiates the concept view of the system.
It contains the following components:
\begin{itemize}
\item \textbf{Business Process.}
The actual, running instance of the business model.

\item \textbf{Accidents.}
All actually happened accidents.

\item \textbf{Attacks.}
All actually happened attacks.

\item \textbf{Security Operations.}
Instances of security measures.
\end{itemize}




\subsection{Procedure}

The analysis procedure is an incremental and iterative process following the four views of the previously described model.

%\includegraphics{../diagrams/png/itsec-ref-model-grimm-procedure.png}
\input{./figures/The-IT-Security-Reference-Analysis-Grimm}

\paragraph*{Step 1. World Analysis}

At first, one has to outline the current state of the system under study. This includes description of:
\begin{itemize}
\item all \textbf{Assets} which must be protected
\item all relevant \textbf{IT-Systems}
\item all involved \textbf{Humans} and their \textbf{Conflicts of Interests}
\item all known \textbf{Vulnerabilities}
\item and all important \textbf{Interactions} between the former components.
\end{itemize}

\paragraph*{Step 2. Potential Analysis}

Secondly, one needs to outline the potential interactions of the system under study.
This includes both the unintended interactions (threads) and the intended interactions (business objectives).
This step produces four artifacts:
\begin{itemize}
\item a \emph{threat specification}, which identifies the threat, its targeted assets, the involved actors and their conflicts of interest.
\item a \emph{threat risk evaluation}, which quantifies the likelihood of a threat manifestation in relation to its associated loss.
\item a \emph{security requirement specification}, which specifies requirements in order to deal with identified hazards
\end{itemize}

\paragraph*{Step 3. Concept Development}

Based on \textbf{Step 2.}, the identified hazards are used alongside realistic accident scenarios and attack techniques to create a \emph{risk matrix}.
With this matrix it is possible to decide if the risk is acceptable or not.
Together with the previously specified security requirements, the matrix is used to define adequate security measures.
Like a business model is an abstract concept to achieve business objectives, this step creates an concept to improve the system's security.

\paragraph*{Step 4. Concept Deployment}

Finally, the security measures have to be implemented.
Additionally, all business operations, accidents, attacks and executed security operations will be recorded in the following time.

The implementation of security measures changes the world view (e.g. IT-systems, actors) and renders the conducted analysis outdated.
So this analysis procedure needs to be conducted again.

\subsection{Abstraction Levels of the Reference Model}

The Reference Model can be used on different levels of abstraction.
This means each component can be used within a wide range of granularity, for instance the security measure \emph{Encryption} can be explored in general or on the level of different concrete encryption tools; or on the even finer level of concrete algorithms.

The utilized abstraction level is not important for the analysis procedure, it depends on the intended audience for the analysis.
However, it is important to use one abstraction level consistently through out the analysis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak

\section{Live+Gov Privacy Protection Analysis}

\subsection{Step 1. World Analysis}

\subsubsection{Assets: Privacy}

In this document we focus our attention to only one asset: The privacy of the citizen.

%TODO: UPDATE
Our definition of privacy is described in detail in Chapter \ref{chap:privacy}. In Section \ref{sec:taxonomy} we define privacy as the ``control over private data'' and introduce the following seven different types of privacy:
\begin{enumerate}
\item Privacy of the Person
\item Privacy of Behaviour and Action
\item Privacy of Communication
\item Privacy of Data and Image
\item Privacy of Thoughts and Feelings
\item Privacy of Location and Space
\item Privacy os Association
\end{enumerate}

Please refer to Section \ref{sec:taxonomy} for more details.

\subsubsection{IT-Systems \& Interactions}
\label{subsubsection:it-systems}

This section outlines the general architecture (Figure \ref{figure:IT Systems}) of IT systems for public monitoring comparable to the Live+Gov project.
This includes a description of it technical infrastructure and the interactions between its components.

The IT infrastructure of the Live+Gov system, i.e. the Live+Gov toolkit and the customization of the software components are described in detail in various project deliverables: D4.1, D4.3, D1.1, D5.1.
In this section we give an abstraction of those systems from the perspective of WP1.

\input{./figures/IT-Systems}

A citizen (a) carries a mobile device running the \emph{sensor collector} (d) application.
The sensor collector application collects sensor data (accelerometer, GPS, GSM, ...) and sends it to the \emph{data center} (c).
The sensor collector can also be able to perform certain data mining operations.
Examples of such data mining operations include human activity recognition,the detection of service lines, detection of characters and faces from images.

The \emph{data center} stores and processes sensor data collected with the sensor collector application.
Again the amount 

Vice versa, it sends beneficial information (traffic jam reports, bus schedule) for \textit{Citizens} to the mobile device.
The \textit{System Provider (b)} provides and operates technical infrastructure like the \textit{Data Center} and the \textit{Report Tool (f)}.
The \textit{Report Tool} queries the \textit{Data Center} for aggregated data to visualize in form of charts and other means suitable to help understanding of monitored \textit{Citizens}. 
\textit{Local Authorities (c)} use the \textit{Report Tool} to get information in order to understand citizen movement and improve public services. 

In such systems, the most valuable information is not the raw sensor data, the beneficial information for \textit{Local Authorities} is produced via \textit{Data Mining} (Human Activity Recognition: detect running, walking, standing, ...). 
Usually, \textit{Data Mining} is heavily conducted within the \textit{Data Center}, but simpler mining processes can also be conducted on mobile devices.



\subsubsection{Actors}
\label{subsubsection:humans}

This section outlines the human actors previously introduced within the IT system architecture (\ref{subsubsection:it-systems}).
It is described which individual interests they have invested in monitoring systems comparable to the Live+Gov system. 
Also the additional actor \textit{Criminal} is introduced as an possible obstacle.

\textbf{Citizen:} 
Citizens are persons who take part in the monitoring system as the monitored subjects.
They offer their privacy sensitive data, because by participating they expect a higher level of comfort in their lives through the offered services in return.
E.g. they will have access to real time bus schedules and traffic jam reports, localized social networking or they generally benefit from public improvement by Local Authorities.

However, they have a legal right to privacy and are interested in having that privacy respected by others.
For example, all humans have a natural interest in physical wellbeing and personal health. 
If someone monitors their immediate location (GPS) or frequently used routes (stalking), people with access to that information could attack and harm citizens.

In general, citizens are not interested in having information about them exploited by others. 
This includes just annoying spam, where their technical identity is used to send unwanted commercials.
But it also includes more severe phishing attacks, which try to rob citizens of their TAN numbers and disrespect their financial interests.

Such financial interests of monitored citizens, the interest in not losing / gaining money, could be disrespected on an even larger scale.
Collected data could be used for scoring and analysis, which may affect the pricing of policies or credits, if sold to insurances or banks.

So citizens have an inherent interest in transparency and disclosure of who uses their data for which purposes, as it may affect their physical and financial wellbeing.

In short, Citizens are interested in ...
\begin{itemize}
\item ... confidential use of privacy sensitive data
\item ... legitimate use of privacy sensitive data
\item ... proportional use of privacy sensitive data
\item ... successful use of privacy sensitive data
\end{itemize}

\textbf{Criminal:}
Criminals are persons who do not have legal access to the IT systems of a proposed monitoring system.
Usually, monetary interests lead their activities.
For example they want to obtain access to critical systems to steal sensitive data or to get the system under their control.
Controlled systems could be leased as part of a bot net. 
Stolen data could simply be sold as is or used for illegitimate purposes, e.g. spam or phishing attacks - or excessive data mining.  

Because Local Authorities are involved in the general outline of a public monitoring system, the possibility for politically motivated attacks cannot be ignored. 
Criminals could want to harm or destroy the systems in order to damage the reputation of Local Authorities (politicians or other officials) or to make a political statement of their own, e.g. "Stop Surveillance!".

Another possible motivation for criminal activities could be social appreciation.
A hacker could attack critical infrastructure just to prove his skills.

In short, Criminals are interested in ...
\begin{itemize}
\item ... financial profit
\item ... high social standing
\item ... political power
\end{itemize}

\textbf{System Provider:}
System Providers provide and operate the technical infrastructure (hardware and software) of the proposed monitoring system.
They are normal companies which offer to provide a service, so different roles of employees are involved:
 an administrator, who maintains and operates the running system;
 a programmer/developer, who develops the system;
 a support manager, who handles customer relations;
 etc.

As companies, they are interested in gaining financial profit.
Among other things, this depends on customer satisfaction, employee happiness and task complexity.
Unsatisfied customers may not want to pay for the service or do not continue the business relation.
Moreover, unsatisfied customers can create a bad reputation, which affects the market for future customers.

Customer satisfaction is connected with the quality of the offered product or service.
This quality depends on the happiness of employees. 
Employees have a claim to professional excellence.
They want to deliver a good job within their means.
If employees cannot satisfy their demand for professional excellence, they might get discontent and deliver poor work.
Moreover, unhappy employees can produce higher costs through sick days.
Ill employees stay on payroll, but stress the project schedule by splitting the workload on fewer heads.
The worst case scenario could be, that a discontent employee gets angry and steals data or harms the running systems.

At last, the financial success of System Providers depends on the task complexity.
The complexity of a task has to be in reasonable bounds, so that System Providers can complete it within time, with a satisfying quality.
If a task has a higher complexity than expected, financial loss is almost determined.
Either System Providers need to hire additional competence to meet schedule and requirements.
Or System Providers they stress the time-line, which also results in a higher man-hour salary ratio and additionally endangers customer satisfaction.
Ultimately, high task complexities can affect employee happiness, if employees cannot complete it within their claim to professional excellence.  

In short, System Providers are interested in ...
\begin{itemize}
\item ... financial profit
\item ... good working conditions
\item ... professional excellence
\item ... reasonable complexity
\end{itemize}


\textbf{Local Authority:} 
Local Authorities are public offices (ministry, agency, department, ...) or other external public service providers which act as direct customers of Service Providers.
They order a proposed monitoring and mining system specialized for their needs. 
For example a low level department, like departments for public mobility, orders a monitoring and mining system to better understand and improve urban traffic flow.

Such systems are heavy investments, so naturally Local Authorities are interested in a profitable return.
However, the return of investment is not directly of financial nature.
Like Service Providers their financial gain depends on customer satisfaction. 
Customers for Local Authorities are either citizens, who use their services, or politicians, who order their services.
The happiness of both sides is interdependent. 
Citizens are happy customers if the services, e.g. public mobility, work well. 
If citizens are happy, it is more likely that politicians gain reputation, as they organize the public services through Local Authorities.

One way of achieving these business objectives is by utilizing business intelligence. 
A proposed monitoring and mining system can provide such intelligence.
For public mobility services it can provide traffic jam detection to maximize traffic flow.
Or it can provide user profiling to maximize (targeted) publicity.

Additionally, since Local Authorities act like corporations comparable to Service Providers, they are also interested in good working conditions.
As discontent employees may harm the system by disclosure of business intelligence.

In short, Local Authorities are interested in ...
\begin{itemize}
\item ... business intelligence
\item ... political reputation
\item ... good working conditions
\end{itemize}


\subsubsection{Conflicts of Interests}
\label{subsubsection:Conflicts of Interests}
This section outlines the Conflicts of Interests (Figure \ref{figure:Live+Gov Conflicts of Interests}) between the actors of the proposed IT system architecture. 
The individual interests of all actors is already described in the previous section and are not elaborated any further.
The emphasis here is put on prominent existing conflicts, because they provide a foundation for vulnerabilities and subsequent threats.

\input{./figures/LG-Conflicts-Of-Interests}


\textbf{System Complexity vs Privacy:}
System Providers offer a service to Local Authorities, which is to provide and maintain a monitoring and mining system, e.g. for public mobility.
This system shall produce business intelligence, so that Local Authorities can improve their public services.
This task in it self has a high technical complexity and is the sole asset with financial return for System Providers.
However, this task operates on privacy sensitive data provided by monitored Citizens.
In order to ensure their privacy, System Provider would have to implement additional mechanisms, which allow Citizens to exercise control of their data.
But this will eventually raise the complexity of the monitoring and mining system.


\textbf{Business Intelligence vs Privacy:}
Local Authorities order a monitoring and mining system from System Providers, which allows them to produce business intelligence for public services.
The system is a heavy investment for Local Authorities, so they are interested in as much intelligence as possible to achieve a profitable return.
But the intelligence is the result of data mining conducted on privacy sensitive data of monitored Citizens.
They are interested in the successful usage of their data, in a sense that they are also benefactors, e.g. improvement of public mobility.
However, the main interest of Citizens lies in maintaining control over their data.
In order do that, they need disclosure of the exact purposes their data is used for, so they can select which data to share.
These purposes cannot be (secretly) exceeded.


\textbf{Money vs Privacy:}
Criminals can gain financial profit from stealing privacy sensitive data.
For example by selling raw contact information to advertisers or by selling mined data to scoring services.
In such cases, Citizens lose complete control over their data.


\textbf{Money vs Professional Reputation:}
Criminals have various business models as optional foundation for attacks on System Providers.
For instance, they can try to invade the infrastructure for e-espionage reasons, to get control over servers to create a bot-net or to steal user data.
All these approaches are motivated by financial interests.
Gathered information can be sold, zombie servers can be leased.
A successful attack proves the technical competence of System Providers wrong and subsequently harms their professional reputation.
This can lead to a loss of future customers or a decrease of stock price for registered companies.
Eventually the financial interests of System Providers are endangered.


\textbf{Political Power vs Political Reputation:}
Besides monetary reasons, Criminals can be motivated by political reasons to attack the monitoring and mining system.
Criminals can break the system to make a political statement of their own, e.g. "Stop Surveillance!".
Or they can steal user data to prove the system insecure.
Both would harm the political reputation of Local Authorities, who endangered the privacy of monitored Citizens.
Criminals would gain political power, because their point of view would seem to be valid.




\subsubsection{Vulnerabilities}
This section outlines the vulnerabilities (Figure \ref{figure:Live+Gov Vulnerabilities}) of the proposed monitoring and mining system.
Note that vulnerabilities are not necessarily of technical nature.
The weaknesses of IT systems are often created due to misuse or misconfiguration of the various components by one or more actors.

\input{./figures/LG-Vulnerabilities}

\textbf{Unencrypted Data Transmission:}
The proposed monitoring and mining system uses HTTP to exchange data between the Sensor Collector, the Data Center and the Report Tool.
Per default, HTTP is a clear text protocol.
This means, one can intercept the connection and read all sensitive information, which is send between the components.
That is: passwords, raw sensor data and data mining results

\textbf{Inadequate Access Rules:}
The proposed IT system infrastructure has various accesses to privacy sensitive data.
System Provider staff has access to Data Center hardware and software like databases, web-servers and other inspection tools.
Local Authority staff has access to the Report Tool.
This all enables staff members to have potential access to privacy sensitive information.
Those accesses have to be secured against unauthorized third parties, e.g. Criminals.
Moreover, we need to ensure that no single person has to many access rights.
For example, a system administrator should not be able to secretly download the whole database on a flash-drive.

\textbf{Insufficiently Secured Infrastructure:}
The proposed monitoring system consists of many hardware and software components, each with its own concrete weaknesses.
For instance, operating systems can be outdated or not subject to frequent updates or virus scans.
Web-applications can be carelessly implemented and not protected against SQL-Injections or Cross-Site-Scripting attacks.
Databases can be ill-configured, so that access from outside the system is possible.
All those weak points can be subject to various known exploit techniques.

\textbf{Unaware Monitoring Subjects:}
We define privacy as one's ability to control information about oneself. 
In order to do that, monitored subjects need to know, that they are monitored, who monitors them, what information is recorded and for what purposes.
Subjects who are not aware of these things cannot effectively preserve control and thus lose their privacy.


\subsection{Step 2. Potential Analysis}

\subsubsection{Threat Specification}

\textbf{Man In The Middle:}
Lorem ipsum dolor suit amet, ...

\textbf{Exploit:}
Lorem ipsum dolor suit amet, ...

\textbf{Corruption:}
Lorem ipsum dolor suit amet, ...

\textbf{Intrasparency:}
Lorem ipsum dolor suit amet, ...

\input{./figures/LG-Threats}
\input{./figures/Threat-Example-1}
\input{./figures/Threat-Example-2}
\input{./figures/ThreatTable}

\subsubsection{Threat Risk Evaluation}

% Todo: use sensor privacy matrix and implicit sensor privacy matrix for threat risk evaluation

\textbf{Sensor Privacy Matrix}

%\includegraphics{../diagrams/png/sensor-privacy-matrix.png}
\input{./figures/LG-Sensor-Privacy-Matrix}

\begin{itemize}

\item
\textbf{Privacy of The Person}

The \textbf{Privacy of The Person} is generally concerned with one could
best understand as \emph{Biometric Privacy}. Friedewald et al. paraphrase
it as \emph{``\om the right to keep body functions and body
characteristics \om private''}. \textbf{Accelerometer},
\textbf{Rotation Vector} and \textbf{Gyroscope} measure the physical
movement of the mobile device on all three axes. If the mobile device
is carried \emph{``normally''} its safe to say that those sensors also
measure the moments of its carrier. So his privacy is infringed
regarding biometric behaviour, as it is captured automatically.
(\textbf{Note:} This is not to be confused with the \textbf{Privacy of
Behaviour and Action} which is used for the social aspects of behaviour
action, e.g.~praying, sexual habits or political activities.)

\item
\textbf{Privacy of Data and Image}

The \textbf{Privacy of Data and Image} demands, that
\emph{``individual's data is not automatically available to other
individuals''}. This type of privacy is trivially threatened because
here sensor data is individual data, a priori. So every sensor violates
the privacy of data and image, as data is transported into a foreign
system where operators have access to it.


\item
\textbf{Privacy of Location and Space}

According to Friedewald et al., the \textbf{Privacy of Location and
Space} is concerned with one's \emph{``right to move about in public or
semi-public space without being identified, tracked or monitored.''}.
This is the location aspect of this type. The space aspect is concerned
with one's \emph{``right to solitude''}, which generally includes one's
right to an inviolate home and other private spaces. Obviously the
\textbf{GPS} and \textbf{GSM} sensors violate such right about not being
tracked, because they reveal the position of the mobile device and its
carrier. The \textbf{GSM} sensor gives the exact cell, the mobile device
has registered with at the current moment. The \textbf{GPS} sensor gives
the current longitude and latitude, the current global position of the
mobile device and its carrier, although there is some artificial
inaccuracy within civil use.

The \textbf{WLAN} and \textbf{Bluetooth} sensors record lists of the
currently available local wireless networks and bluetooth clients. If
such are known stationary entities, those sensors are considered as
dangerous as the \textbf{GSM} sensor for the carriers locational
privacy.

The \textbf{Magnetic field} sensor is not regarded very dangerous to the
carrier's privacy, because it does not allow very precise localization.
But it can limit the possibilities for the global position of the mobile
device. Here, it is just named for completeness sake.

\item
\textbf{Privacy of Associtation}

The \textbf{Privacy of Association} sates that everyone has the
\emph{``right to associate with whomever they wish, without being
monitored [automatically without reasonable suspicion]''}. This
includes individuals and organizations. \textbf{WLAN} and
\textbf{Bluetooth} sensors provide the ability to monitor such
associations if their lists contain known entities. If one frequently
connects with an organizational wireless network, e.g.~an university
network, an association can be deduced (student or staff). The same goes
for the \textbf{Bluetooth} sensor, if it is stationary. Additionally, if
the recorded bluetooth clients are mobile, it is more or less possible
to deduce association with the technical identity of (yet) anonymous
individuals.

Additionally, the \textbf{GSM} sensor could provide the association with
the GSM operator (\textbf{NEEDS TO BE VERIFIED!}).

\end{itemize}







\subsubsection{Security Requirement Specification}


\subsection{Step 3. Plan Development}

\subsection{Legal Privacy Requirements} \ref{sec:LEGAL_REQ}

\subsubsection{Security Measures}

\textbf{The 7 C's of user privacy control (Figure \ref{figure:The Seven Cs of User Privacy Control})}

This is a note on an excerpt from the article \emph{Sociotechnical
Architecture for Online Privacy} \cite{1} called
\textbf{The 7 C's of user privacy control}. Those 7 C's are aspects
which should be covered by measures for implementing user privacy. They
derive from an interpretation of privacy which could be summarized as
\emph{``One's ability to control/seclude information about oneself''}.

%\includegraphics{../diagrams/png/The7Cs.png}
\input{./figures/The-7-Cs-Of-User-Privacy-Control}

\begin{itemize}


\item
\textbf{Comprehension}

\emph{``Users should \textbf{understand} ho personal identifiable
information (PII) is handled, who's collecting it and for what purpose,
and who will process the PII and for what purpose. Users are entitled
to know all parties that can access their PII, the limits to processing
transparency, why the PII data is being requested, when the data will
expire (Either from a collection or database), and what happens to it
after that. This category also include legal rights around PII, and the
implications of a contract when one is formed.''}

This C implements transparency regarding user data and user privacy.
Comprehension should answer the following questions:

\begin{itemize}

\item
  \emph{WHO} collects data?
\item
  \emph{WHAT} data will be collected?
\item
  \emph{WHY} will data be collected and processed?
\item
  \emph{HOW} will data be collected and processed?
\item
  \emph{WHEN} will data expire?
\item
  What is allowed?
\item
  What choices ar possible?
\end{itemize}

All in all information of what's happening and why has to made
accessible for users.

\item
\textbf{Consciousness \textbf{(critical!)}}

\emph{``Users should \textbf{be aware} of when data collections occurs,
when a contract is being formed between a user and data collector when
their PII is set to expire, who's collecting the data, with whom the
data will be shared, how to subsequently access the PII, and the
purposes for which the data is being collected.''}

This C seems to be critical for privacy protection. Consciousness
complements Comprehension in respect that the latter just states that
hard facts need to be delivered. However, those facts might get hidden
in a terms and conditions section which nobody reads but still accepts
anyway. In order to prevent that Consciousness states that a certain
level of \textbf{Awareness} of those facts needs to be established.

\item
\textbf{Choice}

\emph{``Users should \textbf{have choices} regarding data collection
activities in terms of opting in or out, whether or not to provide data,
and how to correct their data.''}

Self explaining. This is the actual control enabled by the 7 C's.

\item
\textbf{Consent}

\emph{``Users must first \textbf{consent} (meaning informed, explicit,
unambiguous agreement) to data collection, use, and storage proposals
for any PII. Privacy consent mechanisms should explicitly incorporate
the mechanisms of comprehension, consciousness, limitations, and
choice.''}

This C might be special case of Choice. Before taking part a user should
have the choice whether to join or not (Opt-In).

\item
\textbf{Context}

\emph{``Users should \textbf{be able to change privacy preferences}
according to context. Situational or physical context - such as crowded
situations (for example, when at a service desk where several people
can listen in on your exchange when you provide a phone number, or when
you're in an online community chat room) - is different from when you
perform a buy transaction with Amazon.com or in rooms with cameras
(where digitization makes the information permanent and unmistakably
you) and data context (such as the sensitivity of data, for example
health data could dictate different actions on the same PII in different
contexts.''}

Self explaining. Refines Choice in context sensitive manner.

\item
\textbf{Confinement}

\emph{``Users should \textbf{be able to set limits} on who may access
their PII, for what purposes, and where and possibly when it may be
stored. Setting limits could provide some good opportunities for future
negotiation between vendors and users.''}

Self explaining. Refines Choice regarding data collection and
processing.

\item
\textbf{Consistency}

\emph{``Users should \textbf{anticipate} with reasonable certainty what
will occur if any action involving their PII is taken. That is, certain
actions should be predictable on user access of PII or giving out of
PII.''}

Information given by Comprehension needs to be reliable to found
choices.



\end{itemize}



\textbf{The 2 Steps of the 7 C's (Figure \ref{figure:The 2 Steps of the 7 Cs of User Privacy Control})}

If we look closer at the 7 C's and how they try to enable control, we
see that a 2 step approach is taken:

%\includegraphics{../diagrams/png/7Cs2Steps.png}
\input{./figures/The-2-Stepos-Of-The-7-Cs-Of-User-Privacy-Control}

\begin{enumerate}

\item
\textbf{Enable \emph{Adequate} Control}

The 7 C's try to enable control through choices. A user should be able
to choose which data can be collected and processed depending on context
and who will have access to the data. But cannot be random. In order to
make substantiated choices and enable \emph{adequate} control a user
needs have

\begin{itemize}

\item
  \textbf{Comprehension:} access to hard facts
\item
  \textbf{Consistency:} trust that those facts are reliable
\item
  \textbf{Consciousness:} awareness of those facts to found choices
\end{itemize}

\item
\textbf{Enable \emph{Actual} Control}

Naturally after creating a certain amount of knowledge, a user needs
also access to opportunities to make use of it. Therefore a user needs
possibilities to actually make choices. Additionally to having choices at
all, the 7 C's have 3 special choice categories:

\begin{itemize}

\item
  \textbf{Choice}
  \begin{itemize}
  \item
    \textbf{Consent:} the choice to opt-in
  \item
    \textbf{Confinement:} the choice to set limits regarding user data
  \item
    \textbf{Context:} the choice to set limits regarding user data
    depending on certain context
  \end{itemize}

\end{itemize}


\end{enumerate}




