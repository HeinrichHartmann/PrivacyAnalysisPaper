\documentclass[runningheads,a4paper]{llncs}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings, color}
\usepackage[bookmarks,bookmarksopen,bookmarksdepth=2]{hyperref}

\graphicspath{ {./img/} }

%% CUSTOM BINDINGS %%

\usepackage{amsmath}

 
\usepackage{alltt}
\newcommand{\TODO}[1]{\begin{alltt}\textcolor{magenta}{TODO: #1}\end{alltt}}

\newenvironment{LGContent}
{ \par\color{blue} \it \small }
{ \par }

\usepackage{verbatim}
% Use this to hide text in TODO commands and LGContent environments.
%\renewcommand{\TODO}[1]{}
%\renewenvironment{LGContent}{ \comment  }{ }
\newenvironment{LGContent-Hidden}{ \comment  }{ }

\usepackage{xspace}
\newcommand{\om}{[...]\xspace} % omission

%% END CUSTOM BINDINGS %%

\begin{document}

%============================================================

\title{Privacy Analysis of a Mobile Sensor Application}
\author{Heinrich Hartmann \and Tim Wambach \and Maximilian Meffert \and R\"udiger Grimm}
\institute{University of Koblenz-Landau}
\maketitle

%============================================================

\begin{abstract}

\TODO{(later)}

\keywords{
privacy protection, IT security analysis, sensor data, mobile phones, traffic survey
}

\end{abstract}

%============================================================

\section{Introduction}

\TODO{RG\\
* Context: Reference model IT Security analysis\\
* Application: Travel Survey\\
* Different definitions of privacy in the literature.\\
* Study outcomes depend on privacy definition
}

\begin{LGContent}
In recent days the importance of privacy protection has been amplified
by the reports about the mass surveillance of ordinary citizens on a
global scale by the NSA and other intelligence agencies around the
world.

While aiming at the noble cause of enhancing eParticipation using
mobile technologies, Live+Gov systems do process a large variety data
that is potentially infringing the citizens privacy. The captured data
includes personal information like name, phone numbers and email
addresses and sensor data from GPS and accelerometer sensors. Also
with some applications it is possible to gather images and textual
input from the citizen.

While the collection of this data is necessary for providing the
advanced services that Live+Gov aims to deliver, at he same time, the
available raw data can be used to draw a very detailed picture of the
private life of the citizen. For instance can GPS location tracking be
used to reveal shopping habits (e.g. when a car seller is visited) and
associations to political groups (when a meeting is
attended). Accelerometer data can be used to infer medical conditions
like walking disabilities. Images can contain faces of nearby persons
to with whom the citizen is associated. All this data is highly
sensitive to the citizens privacy and can be used against the citizen
if it falls in the wrong hands.

The great importance of protecting the citizens privacy should be
apparent from these examples. The European Union, as well as many
other countries in the past, has set out a number of directives that
regulate the collection, processing and use of privacy sensitive
data. We explain the most relevant legislation in Section
\ref{sec:legal}.

The ethical aspects of privacy have been the subject of study of many
social scientists and philosophers. One scholar which is particularly
relevant in our context is Charles Fried. He investiages, why we are
intuitively so sensitive to violations of our privacy. For him privacy
is not asserted as an intrinsic value by itself, he rather sated:

\begin{quote}
Privacy is not simply an absence of information about us in the minds of others;
rather it is the control we have over information about ourselves.
\end{quote}

Fried`s study on the understanding of privacy provided a great
contribution to the research on the same term in philosophy and
computer science and despite the fact his text was published in 1970,
he already included technologies to its viewpoint (like location
monitoring) that are particularly relevant to our Context.  We explain
his theory in \ref{sec:ethics} and follow his definition of privacy in
this document.

In this document we perform a thorough analysis of how to protect the
privacy of a citizen and present several implementations that form the
core of our privacy aware Sensor Data Storage and Mining Infrastructure.

We identify six main threats for the citizens privacy, and derive
eight recommendations that should be followed in order to reduce the
associated risks for hazards.  This analysis form the guideline for
the selection of 9 measures that were implemented in our system and
documented in Chapter \ref{chap:impl}.
\end{LGContent}

%============================================================

\section{Scenario Description: Mobile Traffic Survey}

\TODO{HH:\\
* System description: (Raw version copied from Privacy Analysis)\\
* Information needs of transport agency\\
}

\subsubsection{IT-Systems \& Interactions}
\label{subsubsection:it-systems}

\begin{LGContent}
This section outlines the general architecture (Figure \ref{figure:IT Systems}) of IT systems for public monitoring comparable to the Live+Gov project.
This includes a description of it technical infrastructure and the interactions between its components.

The IT infrastructure of the Live+Gov system, i.e. the Live+Gov toolkit and the customization of the software components are described in detail in various project deliverables: D4.1, D4.3, D1.1, D5.1.
In this section we give an abstraction of those systems from the perspective of WP1.

\input{./figures/IT-Systems}

A \emph{citizen} (a) carries a mobile device running the \emph{sensor collector} application (d).
The sensor collector application is able to collect various kinds of sensor data (accelerometer, GPS, GSM, ...) and can sent the raw data back to the \emph{data center} (c).
The sensor collector can also be able to perform certain data mining operations.

Examples of such data mining operations include human activity recognition,the detection of service lines, detection of characters and faces from images.

In the Live+Gov Project mobile devices are used in particular for the following activities:
\begin{enumerate}
\item collection of GPS samples,
\item mining of Human activities (HAR) based on accelerometer samples,
\item collection of reports consisting of an image, free text and selected categories.
\end{enumerate}

The \emph{data center} stores and processes sensor data collected with the sensor collector application. It can also take into account data obtained from third parties, like the current positions of trains.
The data center can sent mining end products (traffic jam reports, bus schedule) back to the mobile device of the citizen.

In the Live+Gov Project data centers, in particular, perform the following activities:
\begin{enumerate}
\item storage of login credentials, name, and email address for each citizen,
\item storage of collected GPS samples (user id, timestamp, GPS location),
\item storage of HAR results (user id, timestamp, HAR result),
\item detection of service lines based received GPS samples (SLD),
\item storage of SLD results (userid, timestamp, SLD result),
\item sent back SLD results to mobile device,
\item storage of received reports (user id, timestamp, report),
\item detection of inherent patterns of the received reports.
\end{enumerate}

The \emph{System Provider} (b) provides and operates technical infrastructure like the Data Center and the \emph{Reporting Tool} (f).
The Reporting Tool queries the Data Center for aggregated data to visualize in form of charts and other means suitable to help understanding of monitored citizens.

\textit{Local Authorities} (c) use the reporting tool to get information in order to understand citizen movement and improve public services.
In such systems, the most valuable information for local authorities is not the raw sensor data, but aggregated views on the mining end products.

In the Live+Gov Project the reporting tools allows, in particular the following queries:
\begin{enumerate}
\item show aggregate information about which routes citizens take starting from a given location,
\item show the average waiting time of a citizen for each bus stop,
\item show routes where citizens where running to catch a bus,
\item show locations of all reports in a given time window,
\item visualize detected patterns in the report data,
\item view individual reports.
\end{enumerate}
\end{LGContent}


%============================================================

\section{Definition of Privacy}

%\TODO{MM:\\
%- Shorten\\
%- DONE - Remove Implicit Type Violations\\
%- Update figure\\
%- RG: Discuss alternative definitions of privacy\\
%}

\noindent
Defining privacy is a challenge which seems impossible. This is well put to words by Serge Gutwirth, who notes:
\begin{quote}
The notion of privacy remains out of the grasp of every academic chasing it. Even when it is cornered by such additional modifiers as `our' privacy, it still finds a way to remain elusive. \cite{Gutwirth}
\end{quote}
In this section we introduce the concept of privacy as control over information.
We specify types of information we have to deal with in the context of privacy.
And finally we outline the impact mobile sensors can have on one's privacy.

\subsection{Privacy as Control over Information}
%We may need to remove the following paragraph depinding on RG's alternative definition of privacy
%Many definitions seem to focus on the vulnerabilities of privacy.
%Thus a great amount of work is invested in finding threats to prohibit instead of describing why privacy is so valuable to us.
%This way around one could derive measures to ensure and secure its value. \cite{7ToP}

%One particular scholar, who did not follow this way of thinking is Charles Fried.
One possible definition of privacy is given by Charles Fried in his work \textit{An Anatomy of Values}\cite{CFried:Privacy}.
He questioned, why we are intuitively sensitive to privacy violations.
But he did not assert privacy as an intrinsic value by itself, he rather stated:
\begin{quote}
\textbf{Privacy is} not simply an absence of information about us in the minds of others;
rather it is \textbf{the control we have over information about ourselves}. \cite{CFried:Privacy}
\end{quote}
According to Fried privacy is our ability to create and modulate the relationships to other humans.
Which makes us intuitively sensitive for its violation, because this affects what defines our identity.
Also, the ability to build and maintain relationships is essential to society.
This is what makes privacy valuable and deserving of protection. 
\cite{sep-privacy}\cite{CFried:Privacy}

\subsubsection{Relationship Creation.}

% Privacy + Trust ~> Relationship
% ===============================
% - A shares intimate information with B
% - A trusts B not to reveal that information by not constantly monitoring B, i.e. respecting B's privacy
% - B has now the possibility to share intimate information with A

We share information of great intimacy only with persons we deem trustworthy. 
Moreover, we trust those persons to not reveal information about us to others by not constantly monitoring them, i.e. respecting their privacy.
Trust needs the possibility of unknown failure.
If we would constantly monitor our partners, they cannot fail unnoticed nor can they willingly share intimate information with us.
By trusting them, we create the possibility for them to share intimate information with us.
\cite{CFried:Privacy}

\subsubsection{Relationship Modulation.}
Fried argues, depending on the person we are interacting with, we are changing the degree of intimacy we share.
If we are to share private information with others, we are most likely aware that this action is privacy related.
In that case we are able to selectively disclose information along the two dimensions of quantity and quality.
\cite{CFried:Privacy}

\subsubsection{Alternative Definitions.}
Using Fried's anatomy of privacy for this analysis is suitable because of two points.
Despite the fact his text was published in 1970, he already included technologies to its viewpoint that did not only monitor location, but also record biometric data \cite{CFried:Privacy}. 
Secondly, the concept of control over information does not enforce data minimization.
Fried's definition complies with what we call \textit{self data protection}, where persons communicate their data self-determined.
This is the opposite of \textit{system data protection}, where the collection of certain data is prohibited. 

\TODO{RG: Discuss alternative definitions of privacy}

%=======================================================================================



\begin{LGContent-Hidden}
Defining privacy is a challenge which seems impossible. This is well put to words by Serge Gutwirth, who notes:

\begin{quote}
The notion of privacy remains out of the grasp of every academic chasing it. Even when it is cornered by such additional modifiers as `our' privacy, it still finds a way to remain elusive. \cite{Gutwirth}
\end{quote}

%Many researchers seem to only ``focus on the ways in which privacy can be infringed'' \cite{7ToP}.
%Thus they try to create taxonomies of \emph{privacy harms} instead of taxonomies of \emph{privacy types}.
%Those two differ in the respect that the former focuses on threats to prohibit whereas the latter focuses on values to protect.
%So one should rather evaluate what aspects are precious about privacy and develop measures to ensure their security than only forbid single actions against it \cite{7ToP}.

Many researchers seem to only ``focus on the ways in which privacy can be infringed'' \cite{7ToP}.
Thus they invest a great amount of work in defining threats to prohibit instead of describing why privacy is so valuable to us.
This way around one could derive measures to ensure and secure its value \cite{7ToP}.
One particular scholar who does this in the context of digital monitoring is Charles Fried.
He questioned, why we are intuitively sensitive to violations of privacy.
But he did not assert privacy as an intrinsic value by itself, he rather sated:

\begin{quote}
Privacy is not simply an absence of information about us in the minds of others;
rather it is \textbf{the control we have over information about ourselves}. \cite{CFried:Privacy}
\end{quote}

According to Fried privacy is a \textit{rational context}.
Which means that one is aware of such context's existence during a rational action.
If we are to share private information with others, we are most likely aware that this action is privacy related.
In that case we are able to selectively disclose information along the two dimensions of quantity and quality.
This leads Fried to his thesis, that privacy is one's ability to create and modulate his or hers social relationships, namely: friendship, love and trust. \cite{CFried:Privacy}

Depending on the conversation partner, we change the degree of intimate information we share if it is a total stranger, colleague, close friend or lover.
With close friends or lovers we share information of great intimacy we do not share with anyone else.
Moreover, we trust those persons to not reveal information about us to others by respecting their privacy.
Trust needs the possibility of unknown failure.
If we would constantly monitor our partners, they cannot fail unnoticed nor can they willingly share that information with us.
Thus they could not trust us anymore. \cite{CFried:Privacy}

So privacy or the its possibility, according to Fried, is the foundation of our core relations: friendship, love and trust.
And thus it is valuable, because those relations are essential to human society \cite{CFried:Privacy}.
Using his anatomy of privacy as foundation of our analysis is suitable because of two points.
At first, Fried's study on the understanding of privacy provided a great contribution to the research on the same term in philosophy \cite{sep-privacy} and computer science \cite{SociotechnicalArchitectureForOnlinePrivacy}.
Secondly, despite the fact his text was published in 1970, he already included technologies to its viewpoint that did not only monitor location, but also record biometric data.
\end{LGContent-Hidden}

\subsection{The Seven Types of Privacy}
\label{sec:privacytypes}

%\begin{LGContent}
In Fried's definition of privacy as control over "information about onself'', the specification of what constitues such information remains open.
There is a vast amount of information that relates to a person and we need to get a better understanding in order to perform a thorough analysis.
To this end we use the the categorization by Friedewald, Finn and Wright \cite{7ToP} called the \textit{Seven Types of Privacy}.
The seven types of privacy are an extension to the four types of privacy by Roger Clarke \cite{RClarke:4ToP}, which are:
\textit{Privacy of the Person},
\textit{Privacy of Personal Behaviour},
\textit{Privacy of Personal Communication},
\textit{Privacy of Personal Data}.
It is important to note, that this categories do not form no taxonomy, since the categories are not mutually exclusive.
For instance a written email is considered personal communication as well as personal data stored on a computer.

Moreover, Friedewald et al. argue that Clarke's taxonomy is outdated and no longer adequate in order to describe the privacy aspect of our modern, technology driven, world.
In order to address this shortcoming they extend the former four to the now introduced seven types privacy as follows:

\begin{enumerate}

\item \textbf{Privacy of the Person}
This privacy type is generally concerned with one could best understand as biometric privacy.
Friedewald et al. paraphrase it as \emph{``\om the right to keep body functions and body characteristics \om private''}.
This includes but is not limited to measures like weight, height or shoulder width;
biometric identifiers like fingerprints and DNA sequences;
or medical conditions such as limping or having a cold.


\item \textbf{Privacy of Behaviour and Action}
This privacy type is concerned with one's activities in public as well as in private spaces.
It includes but is not limited to religious practices, political activities and sexual preferences or habits.


\item \textbf{Privacy of Communication}
This privacy type is concerned with one's communication in a broad sense.
It includes written correspondence, but also conversations conducted either vis-a-vis or via electronic devices.
Friedewald et al. put it as the right to free discussion without unknown interception by third parties.


\item \textbf{Privacy of Data and Image}
This privacy type is concerned with the secrecy of personal data, especially its automatic disclosure to other individuals and organizations.
It includes data such as paychecks, insurance information or records of public administration.
However, it also refers to pictures taken without consent and digital identifiers like IP addresses or social security numbers.


\item \textbf{Privacy of Thoughts and Feelings}
This privacy type is the counterpart to Privacy of the Person like body and mind are counterparts of one another.
Comparable to the Privacy of Data and Image, Friedewald et al. state that one's thoughts and feelings must not be automatically revealed to others.
This could simply happen by the disclosure of one's diary or by technologies which allow emotion detection through biometric means.
One's body temperature or iris reflexes might infer stress or excitation.


\item \textbf{Privacy of Location and Space}
This privacy type is concerned with one's movements in public spaces and the protection of private spaces.
Friedewald et al. qualify the first dimension as one's right to move without being identified, tracked or monitored.
The second dimension is qualified as one's general right to solitude, especially the right to the inviolability of the home.


\item \textbf{Privacy of Association}
This privacy type is also put as group privacy.
Friedewald et al. state that one must have the possibility with whomever without being recorded.
Associations like friends or organizations such as political parties must not automatically be recorded because one associates with them, and vice-versa.
\end{enumerate}

%\end{LGContent}


\subsection{Sensor Data Privacy Impact}
\label{sec:SensorPrivacyImpact}

In this section we analyze the impact of the disclosure sensor data and certain processing results to the citizens privacy.
This analyisis builds upon the preceeding analyis, but is more focused on the concrete type of data vailable.
For example, the disclosure of Service Line Detection results, does violate the Privacy of Location and Space but not the Privacy of Association that is violated by general GPS tracking.

\begin{figure}
\newcommand{\tcell}[1]{\parbox[c]{4cm}{\vspace{3mm}#1\vspace{3mm}}}
\newcommand{\thead}[1]{\tcell{\Large\centering\textbf{#1}}}
\newcommand{\tbody}[1]{\tcell{\Large\centering #1}}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|c||c|c|c|c|c|c|c|}
\hline
& \thead{Pricacy of the Person}
& \thead{Pricacy of Behaviour and Action}
& \thead{Pricacy of Communication}
& \thead{Pricacy of Data and Image}
& \thead{Pricacy of Thoughts and Feelings}
& \thead{Pricacy of Location and Space}
& \thead{Pricacy of Association}
\\\hline\hline
\thead{Geo Position}
& \tbody{0.5} % Pricacy of the Person
& \tbody{0.5} % Pricacy of Behaviour and Action
& \tbody{0} % Pricacy of Communication
& \tbody{1} % Pricacy of Data and Image
& \tbody{0} % Pricacy of Thoughts and Feelings
& \tbody{1} % Pricacy of Location and Space
& \tbody{0.5} % Pricacy of Association
\\\hline
\thead{Motion}
& \tbody{1} % Pricacy of the Person
& \tbody{0.5} % Pricacy of Behaviour and Action
& \tbody{0} % Pricacy of Communication
& \tbody{1} % Pricacy of Data and Image
& \tbody{0} % Pricacy of Thoughts and Feelings
& \tbody{0} % Pricacy of Location and Space
& \tbody{0} % Pricacy of Association
\\\hline
\thead{Networking}
& \tbody{0.5} % Pricacy of the Person
& \tbody{0.5} % Pricacy of Behaviour and Action
& \tbody{0} % Pricacy of Communication
& \tbody{1} % Pricacy of Data and Image
& \tbody{0} % Pricacy of Thoughts and Feelings
& \tbody{1} % Pricacy of Location and Space
& \tbody{1} % Pricacy of Association
\\\hline
%\thead{HAR}
%& \tbody{-} % Pricacy of the Person
%& \tbody{-} % Pricacy of Behaviour and Action
%& \tbody{-} % Pricacy of Communication
%& \tbody{-} % Pricacy of Data and Image
%& \tbody{-} % Pricacy of Thoughts and Feelings
%& \tbody{-} % Pricacy of Location and Space
%& \tbody{-} % Pricacy of Association
%\\\hline
%\thead{SLD}
%& \tbody{-} % Pricacy of the Person
%& \tbody{-} % Pricacy of Behaviour and Action
%& \tbody{-} % Pricacy of Communication
%& \tbody{-} % Pricacy of Data and Image
%& \tbody{-} % Pricacy of Thoughts and Feelings
%& \tbody{-} % Pricacy of Location and Space
%& \tbody{-} % Pricacy of Association
%\\\hline
\end{tabular}
}
\newline
\newline
{\scriptsize 
0: No Impact,
0.5: Light Impact,
1: Hard Impact}
\caption{Sensor Data Privacy Impact Matrix}
\label{figure:Sensor Data Privacy Impact Matrix}
\end{figure}

\subsubsection{GPS Data.}
The GPS sensor gives the current longitude and latitude, the current global position of the mobile device and its carrier, although there is some artificial inaccuracy within civil use. Threefore, the collection of GPS data violates directly the citizens privacy of Location and Space, and the privacy of Data an Image.

By inference we also get implicit violations of the Privacy of the Person, Privacy of Behavior and Action and Privacy of Association.

\subsubsection{Motion Sensors.}
Accelerometer, Rotation Vector, Gyroscope and Magnetic field sensor measure the physical movement of the mobile device on all three axes.
If the mobile device is carried ``normally'' its safe to say that those sensors also measure the moments of its carrier.
So his privacy is infringed regarding biometric behaviour, as it is captured automatically
Privacy of Data and Image is trivially threatened because here sensor data is individual data, a priori.

By inference we also get implicit violations of the Privacy of Behavior and Action.

\subsubsection{Network Sensors.}
The GSM and WLAN sensors reveal the position of the mobile device and its carrier, when used in connection with external databases.
The GSM sensor gives the exact cell, the mobile device has registered with at the current moment.

The Bluetooth sensors record lists of the bluetooth clients in the direct neighbourhood.
Since those clients are usually moving, inference of the position is usually not possible.
Instead, bluetooth clients carried by a third person may infringe the Privacy of Association.

A similar argumentat applies to WLAN snsors. If one frequently connects with an organizational wireless network, e.g.~an university network, an association can be deduced (student or staff).

%\subsubsection{Human Activity Recognition.}
%The detection and collection of human activities like walking, standing and running, can interfer with the Privacy of the Person, e.g.~since these movement patterns can be indicators for a person's health. Also, trivially, Privacy of Data and Image is violated.
%
%\subsubsection{Service Line Detection.}
%The detection and collection of the service line the user currently uses in the public transportation system allows inference of the location of the user, at least when entering and leaving those service lines at e.g.~bus stops.
%Implicit privacy violations apply accordingly.


\begin{LGContent-Hidden}

%\input{./figures/LG-Implicit-Sensor-Privacy-Matrix}

%TODO: Reformulate the section.
% - Too much overlap with preceeding sections.
% - Structure should be per Sensor Type
% - Add HAR and SLD!

In this section we analyze the impact of the disclosure sensor data and certain processing results to the citizens privacy.
This analyisis builds upon the preceeding analyis, but is more focused on the concrete type of data vailable.
For example, the disclosure of Service Line Detection results, does violate the Privacy of Location and Space but not the Privacy of Association that is violated by general GPS tracking.

\textbf{GPS Data}.
The GPS sensor gives the current longitude and latitude, the current global position of the mobile device and its carrier, although there is some artificial inaccuracy within civil use. Threefore, the collection of GPS data violates directly the citizens privacy of Location and Space, and the privacy of Data an Image.

By inference we also get implicit violations of the Privacy of the Person, Privacy of Behavior and Action and Privacy of Association.

\textbf{Motion Sensors.}
Accelerometer, Rotation Vector, Gyroscope and Magnetic field sensor measure the physical movement of the mobile device on all three axes.
If the mobile device is carried ``normally'' its safe to say that those sensors also measure the moments of its carrier.
So his privacy is infringed regarding biometric behaviour, as it is captured automatically
Privacy of Data and Image is trivially threatened because here sensor data is individual data, a priori.

By inference we also get implicit violations of the Privacy of Behavior and Action.

\textbf{Network Sensors.}
The GSM and WLAN sensors reveal the position of the mobile device and its carrier, when used in connection with external databases.
The GSM sensor gives the exact cell, the mobile device has registered with at the current moment.

The Bluetooth sensors record lists of the bluetooth clients in the direct neighbourhood.
Since those clients are usually moving, inference of the position is usually not possible.
Instead, bluetooth clients carried by a third person may infringe the Privacy of Association.

A similar argumentat applies to WLAN snsors. If one frequently connects with an organizational wireless network, e.g.~an university network, an association can be deduced (student or staff).

\textbf{Human Activity Recognition.}
The detection and collection of human activities like walking, standing and running, can interfer with the Privacy of the Person, e.g.~since these movement patterns can be indicators for a person's health. Also, trivially, Privacy of Data and Image is violated.

\textbf{Service Line Detection.}
The detection and collection of the service line the user currently uses in the public transportation system allows inference of the location of the user, at least when entering and leaving those service lines at e.g.~bus stops.
Implicit privacy violations apply accordingly.

\end{LGContent-Hidden}

%============================================================

\section{IT Security Reference Model}

\TODO{TW}

\begin{LGContent}

The goal of this chapter to analyze and identify the threads to
personal privacy that are posed by collecting, storing and processing
sensor data from mobile phones.  We derive concrete privacy protection
measures that address the main risks involved with handling such data.

The complexity of our systems and the variety of threads make a great
number of counter measures plausible.  We approach this complexity
with the aid of a general security analysis model developed in
\cite{Grimm:ItSecRefModel}.  We give a brief introduction to this
model and perform a IT Security Analysis with respect to the privacy
asset for our system.

We follow the Reference Model for IT Security Analysis as described in
\cite{Grimm:ItSecRefModel}.  It supersedes earlier efforts by
e.g. \cite{Avizienis}.  The reference model consists of a \emph{model}
and a \emph{procedure}.  The model aims to organize common security
terminology in a reasonable and practical way.  The procedure
describes a method to analysis the IT system based on that model.  In
this section we give a brief overview over the reference model.

\subsection{Model}

%\includegraphics{../diagrams/png/itsec-ref-model-grimm.png}
\input{./figures/The-IT-Security-Reference-Model-Grimm}

The model is depicted in Figure \ref{fig:refmodel}.  It is organized
in four views (round boxes) that contain a number of components
(rectangular boxes).

%%%%%%%%%%%%%%%%%%%%

The \emph{world view} contains all components describing the current state.
It consists of the following components:
\begin{itemize}
\item \textbf{Actors.}
All identifiable stakeholders of the system under study.
Typical actors include, users, developers, clients and externals.

\item
\textbf{Assets.} Things of value to one or more stakeholders.
The value can be hard (money, data, etc.) or soft (trust, privacy,etc.).
In our case the only asset we are concerned with is the privacy of the citizen.

\item \textbf{IT-Systems.}
The relevant IT-Systems under study. This encompasses hardware (e.g. servers, network infrastructure), as well as software and third party services.
The level of granularity has to be detailed enough to express all possible threats to the assets at stake.

\item \textbf{Conflicts of Interests.}
Different actors have different interests which can be in conflict which each other.
These conflicts of interest are the origin of all attacks to the system.

A typical conflict is the \emph{Criminal-User-Conflict}:
A user wants to keep control over their private data.
A criminal wants to gain money.
The possibility of selling private data (user profiles) to advertisers, renders both interests conflicting.

\item \textbf{Vulnerabilities.}
All identifiable weaknesses in the IT-System.

In the example of the criminal-user-conflict, the criminal has to exploit a vulnerability, e.g. a weak password, to gain access to the private data about the user.

\item \textbf{Interactions.}
This point captures all possible interactions between assets, IT-Systems, humans and vulnerabilites.
It is described in more detail in the next view.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%


The \emph{potential view} displays the intended and unintended interactions of the components in the world view.
The intended interactions support the underlying business objectives.
Unintended interactions lead to threats.
The potential view consists of the following components.
\begin{itemize}
\item \textbf{Business Objectives.}
Interaction of IT-system and actors that realize a business goals of the system owner.

\item \textbf{Threats.}
A threat is a potential interaction that destroys or harms assets of the system.
Concrete realizations of threats can be \emph{attacks} or \emph{accidents}.
Attacks are executed by an actor in response to a conflict of interest.
Accidents are harmful interactions that are not willfully caused by an actor.

\item \textbf{Chances/Risk.}
Evaluation of chances and risks associated to the business objectives and threats.
The risk associated to a threat is its expected loss.
A chance associated to a intended interaction is its expected gain.

In the case that, the loss can be quantified monetary, and the likelihood of occurrence of a threat can
be modeled probabilistically, the risk is given by the product
\[ \text{risk} = \text{loss} \cdot P[\text{threat}]. \]
In practice such a quantitative risk evaluation is often not possible, and a qualitative, heuristic, analysis is performed instead.

\item \textbf{Security Requirements.}
A set of interactions (e.g. threats) that shall not occur within the system in order to achieve its business objectives.
Security requirements are targeted to protect one or more assets.

An example of a security requirement is that a given communication channel shall not be infringed by externals.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%


The \emph{concept view} is a realization of the potential view of the system.
It specifies important interactions that require further planning.
It contains the following components:
\begin{itemize}
\item \textbf{Business Model.}
The plan to achieve business objectives.

\item \textbf{Accident Scenario.}
A concrete outline of an interaction that leads to an accident.
In particular the asset under threatened and exploited vulnerability need to be described.

\item \textbf{Attack Technique.}
A specific technique or technology to attack IT-Systems (Man in the Middle, Phishing, etc.).
In particular the attacking actor, the conflict of interest and the exploited vulnerability need to be described.

\item \textbf{Security Measures.}
It describes a plan of sufficient measures to secure the intended interactions and to avoid the unintended interactions.
Each security measure targets a vulnerability of the system in order to reduce a risk for a certain thread.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%


The \emph{event view} contains all actual events through out the lifetime of the system.
The event view instantiates the concept view of the system.
It contains the following components:
\begin{itemize}
\item \textbf{Business Process.}
The actual, running instance of the business model.

\item \textbf{Accidents.}
All actually happened accidents.

\item \textbf{Attacks.}
All actually happened attacks.

\item \textbf{Security Operations.}
Instances of security measures.
\end{itemize}


\subsection{Procedure}

The analysis procedure is an incremental and iterative process following the four views of the previously described model.

%\includegraphics{../diagrams/png/itsec-ref-model-grimm-procedure.png}
\input{./figures/The-IT-Security-Reference-Analysis-Grimm}

\paragraph*{Step 1. World Analysis}

At first, one has to outline the current state of the system under study. This includes description of:
\begin{itemize}
\item all \textbf{Assets} which must be protected
\item all relevant \textbf{IT-Systems}
\item all involved \textbf{Humans} and their \textbf{Conflicts of Interests}
\item all known \textbf{Vulnerabilities}
\item and all important \textbf{Interactions} between the former components.
\end{itemize}

\paragraph*{Step 2. Potential Analysis}

Secondly, one needs to outline the potential interactions of the system under study.
This includes both the unintended interactions (threads) and the intended interactions (business objectives).
This step produces four artifacts:
\begin{itemize}
\item a \emph{threat specification}, which identifies the threat, its targeted assets, the involved actors and their conflicts of interest.
\item a \emph{threat risk evaluation}, which quantifies the likelihood of a threat manifestation in relation to its associated loss.
\item a \emph{security requirement specification}, which specifies requirements in order to deal with identified hazards
\end{itemize}

\paragraph*{Step 3. Concept Development}

Based on \textbf{Step 2.}, the identified hazards are used alongside realistic accident scenarios and attack techniques to create a \emph{risk matrix}.
With this matrix it is possible to decide if the risk is acceptable or not.
Together with the previously specified security requirements, the matrix is used to define adequate security measures.
Like a business model is an abstract concept to achieve business objectives, this step creates an concept to improve the system's security.

\paragraph*{Step 4. Concept Deployment}

Finally, the security measures have to be implemented.
Additionally, all business operations, accidents, attacks and executed security operations will be recorded in the following time.

The implementation of security measures changes the world view (e.g. IT-systems, actors) and renders the conducted analysis outdated.
So this analysis procedure needs to be conducted again.

\subsection{Abstraction Levels of the Reference Model}

The Reference Model can be used on different levels of abstraction.
This means each component can be used within a wide range of granularity, for instance the security measure \emph{Encryption} can be explored in general or on the level of different concrete encryption tools; or on the even finer level of concrete algorithms.

The utilized abstraction level is not important for the analysis procedure, it depends on the intended audience for the analysis.
However, it is important to use one abstraction level consistently through out the analysis.
\end{LGContent}

\section{Privacy Analysis}

\TODO{TW}

\begin{LGContent}
\subsection{Step 1. World Analysis}

\subsubsection{Assets: Privacy}

In this document we focus our attention to only one asset: The privacy of the citizen.

%TODO: UPDATE
Our definition of privacy is described in detail in Chapter \ref{chap:privacy}. In Section \ref{sec:taxonomy} we define privacy as the ``control over private data'' and introduce the following seven different types of privacy:
\begin{enumerate}
\item Privacy of the Person
\item Privacy of Behaviour and Action
\item Privacy of Communication
\item Privacy of Data and Image
\item Privacy of Thoughts and Feelings
\item Privacy of Location and Space
\item Privacy os Association
\end{enumerate}

We refer to Section \ref{sec:taxonomy} for more details.


%
%
% SECTION: IT SYSTEM DESCRIPTION MOVED ABOVE
%
%


\subsubsection{Actors}
\label{subsubsection:humans}

This section describes the human actors previously introduced within the IT system architecture (\ref{subsubsection:it-systems}).
Also the additional actor \textit{External} is introduced as a person with no special access rights.

\textbf{Citizen.}
Citizens are persons who use the mobile device as users of the provided software.
Their main motivation for using the software is to gain a higher level of convenience in their daily activities. For example they may have access to real time bus schedules or reports about traffic jams, that help them to avoid long waiting times.
Also they generally benefit from improvements of public infrastructure by local authorities, which is triggered by issue reports.

By using the application citizens are sharing personal information like name and address, as well as data gathered from mobile sensor with the service provider.
This data can be exploited in ways that are harmful to the citizen.
This need to protect this protection is manifest in several laws and constitutions as the right to privacy and data protection.
The citizen has a vital interest in having his legal rights protected and enforced.

If the right to privacy is violated, there is a magnitude of potential harms that interfere with other interests of the citizen.
This includes just annoying spam, where their technical identity is used to send unwanted commercials.
More severe phishing attacks can exploit personal information, and try to manipulate citizens into disclosing credentials like TAN numbers and disrespect their financial interests.
Information about the current location (GPS) or frequently used routes (stalking) can be used to attack and directly harm the health of the citizen.
Information about medical conditions inferred by sensor data (e.g. fintness trackers) are of interest to insurance companies, which may affect the pricing of policies and can interfere with financial interests of the citizen.

Also it is well established (cf. \cite{GuardienMassSurveillance}) that the very act of being monitored can have impact on mental health and performance, promotes distrust and breeds conformity.

In short, citizens are interested in
\begin{itemize}
\item physical wellbeing and health
\item financial profit
\item convenience
\item legitimate use of personal data
\item non-disclosure of personal data to peers of the citizen
\item not being monitored.
\end{itemize}

\textbf{External.}
Externals are persons who do not have privileged access to the IT systems, and are willing to break laws, security constrains and norms in order to promote their interests.

If the external is in some kind of relationship to the citizen, like a friendship or business partnership, the external can have a direct interest in gaining information about the citizen in order to increase their power.

Another common interest of an external is financial profit. For example they want to obtain access to critical systems to steal sensitive data or to get the system under their control.
Controlled systems could be leased as part of a bot net.
Stolen data could simply be sold as is or used for illegitimate purposes, e.g. spam or phishing attacks - or excessive data mining.

Because local authorities are involved in the general outline of the Live+Gov system, the possibility for politically motivated attacks is given.

Externals could want to harm or destroy the systems in order to damage the reputation of local authorities (politicians or other officials) or to make a political statement of their own.

Another possible motivation for external  activities could be social appreciation.
A hacker could attack critical infrastructure just to prove his skills.

In short, externals are interested in
\begin{itemize}
\item increase power over citizen
\item financial profit
\item political activism
\item social standing.
\end{itemize}

\textbf{System Provider.}
System Providers operate the technical infrastructure (hardware and software) of the IT System.
They are private companies and legal persons in their own right, but also employ a number of people with diverging interests, including:
administrators, who maintain and operate the running system;
programmer/developer, who develop the system;
a support manager, who handles customer relations.

As companies, they are interested in gaining financial profit.
Among other things, this depends on customer satisfaction, employee happiness and task complexity.
Unsatisfied customers may not want to pay for the service or do not continue the business relation.
Moreover, unsatisfied customers can create a bad reputation, which affects the market for future customers.

Customer satisfaction is connected with the quality of the offered product or service.
This quality depends on the happiness of employees.
Employees have a claim to professional excellence.
They want to deliver a good job within their means.
If employees cannot satisfy their demand for professional excellence, they might get discontent and deliver poor work.
Moreover, unhappy employees can produce higher costs through sick days.
The worst case scenario could be, that a discontent employee gets angry and steals data or harms the running systems.

At last, the financial success of system providers depends on the task complexity of the maintained infrastructure.
The complexity of a task has to be in reasonable bounds, so that system providers can complete it within time, with a satisfying quality.
If a task has a higher complexity than expected, financial loss is almost certain.
Either System Providers need to hire additional competence to meet schedule and requirements.
Or system providers they stress the time-line, which also results in a higher man-hour salary ratio and additionally endangers customer satisfaction.
Ultimately, high task complexities can affect employee happiness, if employees cannot complete it within their claim to professional excellence.

In short, System Providers are interested in
\begin{itemize}
\item financial profit
\item good working conditions
\item professional excellence
\item manageable complexity.
\end{itemize}


\textbf{Local Authority.}
Local authorities are public offices (ministry, agency, department, ...) or other external public entities which act as direct customers of service providers.
They purchase a system specialized for their needs.
For example a department for urban mobility, orders a system to better understand usage patterns and make improvement to the urban traffic flow.

Such systems are investments, and so naturally local authorities are interested in a profitable return, like increased ticket sales.
However, the return of investment is not directly of financial nature.
Like service providers their financial gain depends on customer satisfaction.
Customers for local authorities are either citizens, who use their services, or politicians, who order their services.
The satisfaction of both sides is interdependent.

Citizens are satisfied customers if the services, e.g. public mobility, work well.
If citizens are happy, it is more likely that politicians gain reputation, as they organize the public services through local authorities.

The first important step of improving the public services is by obtaining business intelligence.
For the urban mobility scenario the Live+Gov systems provide insight in form of traffic jam detection and usage pattern mining, which allow local authorities to focus their efforts to the most important sites.

Additionally, since local authorities act like corporations comparable to service providers, they are also interested in good working conditions.
Discontent employees may harm the system by e.g. disclosure of privacy sensitive data.

In short, local authorities are interested in
\begin{itemize}
\item financial profit
\item political reputation
\item business intelligence
\item good working conditions.
\end{itemize}


\subsubsection{Conflicts of Interests}
\label{subsubsection:Conflicts of Interests}
This section outlines the Conflicts of Interests (Figure \ref{figure:Live+Gov Conflicts of Interests}) between the actors of the proposed IT system architecture.

The individual interests of all actors is already described in the previous section and are not elaborated any further.
The emphasis here is put on prominent existing conflicts, because they provide a foundation for vulnerabilities and subsequent threats.

\input{./figures/LG-Conflicts-Of-Interests}
%TODO: Adapt Figure

\textbf{System Complexity vs Privacy.}
System Providers offer a service to Local Authorities, which is to provide and maintain a monitoring and mining system, e.g. for public mobility.
This system shall produce business intelligence, so that Local Authorities can improve their public services.
This task in it self has a high technical complexity and is the sole asset with financial return for System Providers.
However, this task operates on privacy sensitive data provided by monitored Citizens.
In order to ensure their privacy, System Provider would have to implement additional mechanisms, which allow Citizens to exercise control of their data.
This will not only raise the complexity of the monitoring and mining system, System Providers also have to layout the complexity in a comprehensible manner.
To effectively enable Citizens to preserve their privacy, they need to know what happens with their data.

\textbf{Business Intelligence vs Privacy.}
Local authorities order a monitoring and mining system from system providers, which allows them to produce business intelligence for public services.
The system is an investment for local authorities, so they are interested in as much intelligence as possible to achieve a profitable return.

The gained intelligence is the result of data mining conducted on privacy sensitive data of participating citizens.
They are interested in the successful usage of their data, in a sense that they are also benefactors, e.g. improvement of public mobility.
The main interest of citizens lies in maintaining control over their data and protecting their rights to privacy.
In order do that, they need full disclosure of the processing steps and the purposes their data is used for, and to be given a choice whether such processing should be allowed for their own data.

\textbf{Power of External vs. Privacy.}
Externals which are in a social relation to the citizen can have an interest in obtaining further information in order to gain power.
In the most simplistic example this could be a man wanting monitor the activities of his spouse.
Another example is a Government spying on it's citizens in order to suppress opposition.
An additional twist in the last example is, that there can be legal regulations that require the service provider to support the Governments invasion of the citizens privacy.

\textbf{Financial Profit of External vs Privacy.}
Externals can gain financial profit from stealing privacy sensitive data.
For example by selling raw contact information to advertisers or by selling mined data to insurance companies, or intermediaries like scoring companies.
In such cases, citizens lose complete control over their data.

\textbf{Financial Profit of External vs Reputation of System Providers.}
Externals have various business models as optional foundation for attacks on System Providers.
For instance, they can try to invade the infrastructure for e-espionage reasons, to get control over servers to create a bot-net or to steal user data.
All these approaches are motivated by financial interests.
Gathered information can be sold, zombie servers can be leased.

A successful attack proves the technical competence of system providers wrong and subsequently harms their professional reputation.
This can lead to a loss of future customers or a decrease of stock price for registered companies.
Eventually also the financial interests of system providers are endangered.

\textbf{Political Activism vs Reputation of Local Authority.}
Besides monetary reasons, externals can be motivated by political reasons to attack the monitoring and mining system.
Externals can break the system to make a political statement of their own,
or they can steal user data to prove the system insecure.
Both would harm the reputation of local authorities, who endangered the privacy of the citizens.


\subsubsection{Vulnerabilities}
\label{subsubsection:Vulnerabilities}
This section outlines the vulnerabilities (Figure \ref{figure:Live+Gov Vulnerabilities}) of the proposed monitoring and mining system.
Note that vulnerabilities are not necessarily of technical nature.
The weaknesses of IT systems are often created due to misuse or misconfiguration of the various components by one or more actors.

\input{./figures/LG-Vulnerabilities}

\textbf{Insecure Infrastructure.}
The proposed monitoring system consists of many hardware and software components, each with its own concrete weaknesses.
For instance, operating systems can be outdated or not subject to frequent updates or virus scans.
Web-applications can be carelessly implemented and not protected against SQL-Injections or Cross-Site-Scripting attacks.
Databases can be ill-configured, so that access from outside the system is possible.
All those weak points can be subject to various known exploit techniques.

\textbf{Insecure Data Transmission.}
The proposed monitoring and mining system uses HTTP to exchange data between the Sensor Collector, the Data Center and the Report Tool.
Per default, HTTP is a clear text protocol.
This means, one can intercept the connection and read all sensitive information, which is send between the components.
That is: passwords, raw sensor data and data mining results

\textbf{Unhappy Employees.}

An Employee that is frustrated with his situation for a long time
period constitutes a security vulnerability. On the one hand he might
want to harm his employer directly, on the other he is increasingly
susceptible for social engineering.

\textbf{Inadequate Access Rules.}
The proposed IT system infrastructure has various accesses to privacy sensitive data.
System Provider staff has access to Data Center hardware and software like databases, web-servers and other inspection tools.
Local Authority staff has access to the Report Tool.
This all enables staff members to have potential access to privacy sensitive information.
Those accesses have to be secured against unauthorized third parties.
Moreover, we need to ensure that no single person has to many access rights.
For example, a system administrator should not be able to secretly download the whole database on a flash-drive.


%TODO: Extend to general missing privacy wareness of citizen, system provider and local authority
\textbf{Unaware Monitoring Subjects.}
We define privacy as one's ability to control information about
oneself.  In order to do that, monitored subjects need to know, that
they are monitored, who monitors them, what information is recorded
and for what purposes.  Subjects who are not aware of these things
cannot effectively preserve control and thus lose their privacy.  This
vulnerability expresses itself as the lack of information material
like a Privacy Policy including concise information about applied
processing steps, access rules and disclosure to 3rd parties.

\subsection{Step 2. Potential Analysis}

\subsubsection{Threat Specification}

\input{./figures/Threat-Example}

Recall from the security model description in Section \ref{sec:GrimmModel}, that a threat is a potential interaction of the components that targets an asset.
We restrict ourselves to the case of attacks, and the asset of privacy.
An attack is an interaction that is executed by an actor in response to a conflict of interest by exploiting a vulnerability of the system.
The alternative interaction of accidents are less relevant for us, since the violation of privacy always requires an actor that takes advantage of personal data.

In Figure \ref{figure:Threat-Example} we illustrate the structure of threats at the example of ``Data Theft".
Here the attack is executed by an external person, that harms the privacy of the citizen.
He is motivated to do so by financial profit gained by selling personal information, which is in conflict with the citizens interest in his privacy.
To get hold of the data the external exploits an insecured HTTP transfer of recorded data.

In this section we describe, in a similar fashion, threats for the citizen privacy in the Live+Gov system.
This list can necessarily not be complete, but we make a best effort to cover the most relevant cases.

% \label{figure:Threats}
\input{./figures/Threats}

\textbf{T1. Insufficient Control Features.}
The System Provider does not offer tools for the Citizen to control his data.
However, besides the missing features he provides a safe and secure system.
This threat contradicts the definition of privacy as control over one's information about oneself.
As soon as collected data of Citizens is stored on System Provider servers, all control over that data is lost.
This is not necessarily due to bad intention, System Providers may simply have forgotten to include such features during the development process.
Although, control capabilities for Citizens add to the system complexity, which could motivate to omit those. 
Therefore interests of Citizens and System Providers are in conflict, namely it is the Citizen's \textit{Privacy vs. System Complexity} for System Providers.
This is an abstract threat provoked by a general \textit{Missing Privacy Awareness} in the minds of all actors in the Live+Gov context.

\textbf{T2. Excessive Data Mining.}
The System Provider and/or the Local Authority secretly extract more private information from the collected data, than the Citizen agreed to.
But results of the mining process create no disadvantages for Citizens, because there is no disclosure to third parties.
This could be the case for a System Provider, who wants to test a new product and uses the pre-existing data collection.
Or for a Local Authority, who wants to analyze the data collection regarding fare evasion.
However, the Citizen has not agreed to such data processing nor could he, since it is conducted secretly.
This disables a Citizen to control his data adequately.
Thus there are two possible conflicts: \textit{Privacy vs. Financial Profit of Serivce Provider} and  \textit{Privacy vs. Buisness Intelligence of Local Authority}
The threat can be provoked by either lax data handling policies of both System Providers and Local Authorities, or a weak law enforcement of existing supervision.
But the main issue, which can lead to such threats, is again a general \textit{Missing Privacy Awareness}.

\textbf{T3. Data Theft}
An External infiltrates infrastructure in order to steal personal data and sell it on the black market.
Also the External might be motivated politically and wants to harm the reputation of the System Provider or the Local Authority.
Anyways, this threat would be manifested through a technical attack on either hardware (Packet Capture) or software (buffer overflow, SQL injection).
Such a successful attack could harm the reputation of both System Provider and Local Authority.
The technical competence of System Providers would be proven wrong, therefore they would lose professional reputation.
Local Authorities would lose their political reputation, as it would seem like they had endangered data of Citizens, which lose complete control.
Thus this threat is defined by three conflicts: \textit{Privacy vs. Financial Profit}, \textit{Reputation of Service Provider vs. Political Activism} and \textit{Reputation of Local Authority vs. Political Activism}.
Also this threat describes the classical scenario, where attacks are provoked by \textit{Insecure Infrastructure} (SQL injection) and \textit{Insecure Communication} (Packet Capture).

\textbf{T4. Surveillance}

An External infiltrates infrastructure in order to obtain information
about the citizen and exploit it directly.  In this scenario the
external is supposed to have some direct relationship to the citizen
which motivates his interest to obtain personal information.  Examples
could be a public institution that wants to gain information about
planned activities of the citizens (e.g. Nixon's Watergate scandal or
the recent prosecution of Guardian journalists by GHCQ).  Another
example is an insurance company that seeks to get information about
the citizens life-style in relation to the insured risk, like car
accidents or health hazards.

In this threat the privacy interest of the citizen is in conflict with
the aspirations for power over the citizen by the externals.

\textbf{T5. Information Leak}

Like an external person the Data Theft Scenario an employee of the
service provider or the Local Authority has selfish interests to gain
money, make political statements or harm his employer.  In order to
pursue this interest he can steal personal data and sell it or release
it to the public.  The corresponding conflicts of interests are:
\textit{Privacy vs. Financial Profit} of the Employee, \textit{Reputation of Service
  Provider vs. Political Activism} of the Employee and \textit{Reputation of Local
  Authority vs. Political Activism} of the Employee.  The vulnerability constitutes of
the existence of \textit{Unhappy employees} itself and possibly \textit{lax access
rules} that enable the employee to obtain large amounts of data
unnoticed.

\textbf{T6. Social Engineering}

This scenario an external manipulates an employee of a Service
Provider or the Local Authority to leak information to the external
person.  It is thus combination of the Data Theft and Information Leak
scenario.
The conflicts of interest are \textit{Privacy vs. Financial Profit} of
the External, \textit{Reputation of Service Provider vs. Political
  Activism} of the external and \textit{Reputation of Local Authority
  vs. Political Activism} of the external.  The exploited
vulnerabilities are, again, the existence of \textit{Unhappy
  employees} and possibly \textit{lax access rules} that enable the
employee to obtain large amounts of data unnoticed.


\subsubsection{Threat Risk Evaluation}

In this section we will associate to every identified threat a corresponding risk.
Recall from \ref{sec:GrimmModel} that a risk is the expected loss that is associated to the threat.
Therefore, we have to quantify the likeliness of the threat to occure and the harm or loss done in this case.
The quantification of likeliness will be solely based on rough judgment of the authors.
The quantification of loss, will be made in a two step process.
For each threat listed in table \ref{firgure:Threats}, we have analyzed the affected personal data of the citizen.
For each possible data type (e.g. GPS) we analyze the impact on the seven different types of privacy in Section \ref{sec:SensorPrivacyImpact}.
In combination we can quantify roughly the impact of each threat on the citizens privacy. Both evaluations are necessarily fraught with a high level of uncertainty.

For the quantification of the loss in case of a threat scenario we use the following rough calibration:
\begin{itemize}
\item 3: High. Leak of information to peers (e.g. public) which impacts citizen.
\item 2: Medium. Undisclosed processing of personal data or disclosure to third parties that are unrelated to subject.
\item 1: Low. Loss of control over data.
\item 0: None
\end{itemize}

For the quantification of likeliness the following scale is used:
\begin{itemize}
\item 4: Always.
\item 3: High. Occurs once in 10 cases
\item 2: Medium. Occurs once in 100 cases
\item 1: Low. Occurs once in 1 million cases
\item 0: Impossible
\end{itemize}

The quantification of the risk, we add the values for loss and
likeliness of the corresponding threats. Note, that loss and
likeliness scales have a logarithmic character, so that that addition
of those scales corresponds to multiplication of the usual scales.


The likeliness, loss and the resulting risks assigned to the threats
are discussed in the following paragraphs and summarized in Figure
\ref{fig:risks}.


\textbf{T1. Insufficient Control Features.}  The occurrence of this
threat is dependent on the design on the system and given in our case,
since we do not give the citizen control over his data once it is
recorded. Therefore the Likeliness is evaluated as $4$ (Always).  The
associated, risk is $1$ Low on our scale, since no direct harm is done to
the citizen by exploiting the data.

Hence the resulting risk is calculated as $4+1 = 5$.

\textbf{T2. Excessive Data Mining.}
We assess the likeliness of excessive data mining to be $3$ High, since
these kind of analysis can be performed within the walls of the service
provider, without somebody else noticing, and the service provider himself
has an interest in this activity.

The associated loss, on the other hand can be substantial (Medium
$2$).  For example when GPS data is linked to data from telephone
books the identity of the citizen can be revealed and personal details
like visits to doctors. In the threat scenario, this information is
not leaked to third parties, (which would justify an even higher loss
assessment), but the very existence of this information violates the
citizens privacy.

Hence the resulting risk is calculated as $3+2 = 5$.

\textbf{T3. Data Theft.}
The likeliness of a targeted attack by a third party is dependent on
the popularity of the offered service and financial value of the
captured information. Moreover, the amount of manual work required to
infiltrate a custom build system is significantly higher that that of
compromising a standard software solution. In the scenario we assume a
moderate popularity in a single metropolitan area, with around 10.000
users and storage of data of only limited financial value (no
addresses, no payment information). Therefore the likeliness
assessment is $1-2$ (Low-Medium).

The harm of leaked information to a criminal party is $3$ High.
Hence the resulting risk is calculated as $4-5$.

\textbf{T4. Surveillance.}  In the surveillance scenario an party
related to the citizen, like a company where he is customer of, or a
government agency, seeks to obtain sensitive information from our
service.

The likeliness of such an intrusion is hard to asses, and depends
again on the popularity of the service. If a high popularity is
reached we have recently learned that spying by government agencies is
very likely to occur. The barrier for companies that do not operate
the infrastructure used to transmit the data a surveillance attack is
however very hard to perform. Therefore we assess the likeliness of
the threat with $1-2$ (Low-Medium).

The harm of leaked information to a related party is $3$ High.
Hence the resulting risk is calculated as $4-5$.

\textbf{T5/6. Information Leak and Social Engineering.}

In our scenario we assume that the culture and ethics inside the
service provider company and local authority are very high, so that
the information leak scenario has a likeliness of $1$ (Low).

The harm of such an information leaked is $3$ High, so that the
resulting risk is calculated as $4$.


\begin{figure}
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Threat}                   & \textbf{Likeliness} & \textbf{Loss} & \textbf{Risk} & \textbf{Recommendation}
\\\hline
T1. Insufficient Control Features & 4                   & 1             & 5             & R1, R2
\\\hline
T2. Excessive Data Mining         & 3                   & 2             & 5             & R3, R4, R5
\\\hline
T3. Data Theft                    & 1 - 2               & 3             & 4 - 5         & R6
\\\hline
T4. Surveillance                  & 1 - 2               & 3             & 4 - 5         & R7
\\\hline
T5. Information Leak              & 1                   & 3             & 4             & R8
\\\hline
T6. Social Engineering            & 1                   & 3             & 4             & R8
\\\hline
\end{tabular}
\caption{Live+Gov Risk Evaluation and Recommendations}
\label{fig:risks}
\end{figure}

\subsubsection{Privacy Recommendations}
\label{sec:prec}

In the preceding section we have identified the main risks for the
users privacy.  In this section we derive recommendations or
requirements for a system that addresses these risks.  Some of these
requirements are implemented as security measures in our systems and
discussed in the following chapter \ref{chap:impl}.

In order to address the threat with the highers risk, Insufficient
Control (T1) of the citizen, we need to give the citizen back the
control over its data inside the system. The most direct way to do
this is to provide a web-based \emph{Privacy Dashboard (R1)} which allows
the citizen to view, edit and delete all information about his person
that is stored inside the system. Also control applied processing and
disclosure of the data to third parties should be given to the user,
at least in the form of an opt-out or veto option.

A necessary pre-requirement for effective control of the citizen over
his data is information and comprehension of the intended data
capturing and processing steps. Therefore a \emph{Privacy Policy (R2)} that
is easily readable and contains all important information is
essential.  Moreover, the existence of a Privacy Policy is a legal
requirement (cf. Section \ref{EUDIR}).

The threat with the second largest risk is (T2) Excessive Data Mining.
Contrary to common belief, it is neither legal nor ethical to process
personal data for by new methods or for new purposes that were not
stated and explained to the citizen at the time of data
collection. Also the common practice of obtaining far-reaching
permissions from the citizens inside the privacy policy is neither an
ethical or legal solution to the problem (cf. Art. 6 in Section
\ref{EUDIR}).

To address this threat awareness about the limitations of data
processors inside the company is a key element. As one mean to
establish such a culture of privacy respect, we recommend to prepare
an document called \emph{Data Handling Guidelines (R3)} intended for
internal use that explains the concrete processing steps and purposes
that are permitted by the citizens. This guideline should also be
structured in a way that it covers the legal notification requirement
from the EU Data Protection Directive (cf. Section \ref{EUDIR}). In
particular the following information should be provided for each
processing task: The name of the controller, purpose of processing,
description of the data categories, recipients of the data if
disclosed, transfer to third countries and a description of security
of processing.

If further processing should be performed, it is necessary to seek
additional permissions from the citizen. A simple email explaining the
planned processing steps, and \emph{asking for permission (R4)} would be
enough for this purpose. The permission can be given via an embedded
link that shall be followed in order to signal agreement.

An alternative measure to address the risk of excessive data mining is
the \emph{anonymization (R5)} of data. When all direct- or indirect
links to the identity of the person are removed, no violation of the
citizens privacy caused by arbitrary processing. However removing all
such links is a challenging tasks, and full anonymity is often not
achieved, cf. \cite{krumm2009}.

The protection from threat scenario (T3) Data Theft is a case of
classical \emph{IT infrastructure security (R6)}. The storage and processing infrastructure has
to be secured using firewalls, up-to data software versions and proper
authentication mechanisms.

The protection from threat scenario (T4) Surveillance focuses on the
communication channels. They are target of wiretapping attacks by
intermediaries or externals with access to the communication
infrastructure. Strong \emph{encryption (R7)} should be used to make
it harder for externals to read the content of the transmitted data.

Threat scenarios (T5) Information Leak and (T6) Social Engineering
target the vulnerability of unhappy employees. Therefore a trustful,
\emph{healthy company culture (R8)} should be maintained.

In summary we recommend the following measures to secure the citizens
privacy:
\begin{enumerate}
\item[R1] Privacy Dashboard. A tool which allows the citizen to view, edit
  and delete all data personal data that is stored in the system.
\item[R2] Privacy Policy. A document, that informs the citizen about the
  collection and processing of personal information. It should at
  least contain the legally required information.
\item[R3] Issue Data Handling Guidelines that explain the permitted
  processing methods and purposes.
\item[R4] Ask the citizens for permissions before applying further
  processing via Email.
\item[R5] Anonymize personal data before processing.
\item[R6] Securing of Storage and Processing infrastructure using e.g. firewalls.
\item[R7] Securing communication channels using encryption.
\item[R8] Maintain a healthy, trustful relationship with your employees.
\end{enumerate}
The mapping of these recommendations to the threats is summarized in Figure \ref{fig:risks}.
\end{LGContent}



%============================================================

\section{Conclusion}

\TODO{later.\\
* Key aspect control, can be given back to citizens via ``Privacy Dashboard''
}

\bibliographystyle{splncs}
\bibliography{paper}{}



\end{document}
